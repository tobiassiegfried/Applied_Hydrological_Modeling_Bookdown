# Retrieval & Analysis of Data {#RetrievalAnalysisHydroData}

## Preliminary Remarks {.unnumbered}

We focus on the Chirchik River as our case study (see Section \@ref(CaseStudyChirchikRiver) for background information on the river basin). The steps for preparation and processing of the required input data for modeling carry over to any other basin that you wish to focus on.

First, we will discuss how to prepare and process the geospatial information of the catchment and its sub-units using the open-source Geographic Information System [QGIS](https://qgis.org/en/site/){target="_blank"}.

Second, we deal with climate data and show how to prepare existing temperature and precipitation data from local stations and also discuss how to access, download and process climate data from reanalysis products. Finally, we prepare the available hydrological data. \TODO: Make sure this is corresponding to the section's content.

For this course, we use the open source software [RS MINERVE](https://www.crealp.ch/fr/accueil/outils-services/logiciels/rs-minerve.html) for physically-based modeling, i.e. for numerical rainfall-runoff modeling and river routing. We then use [R](https://www.r-project.org){target="_blank"} for empirical modeling. Hence, the steps described here focus on the input requirements of this software. It should be noted, however, that other modeling packages exist with which hydrological-hydraulic modeling can be carried out in a similar manner. These include

-   [WEAP: Water Evaluation and Planning System](https://www.weap21.org){target="_blank"},
-   [SWAT: Soil & Water Assessment Tool](https://swat.tamu.edu){target="_blank"}, and
-   [Mike Hydro Basin](https://www.mikepoweredbydhi.com/products/mike-hydro-basin){target="_blank"}

As some of these modeling packages are license-based, the advantage of using the combination of QGIS, R and RS MINERVE is that this is a completely free software suit for any user and use scenario.

\TODO: Maybe revise... In the Chapter \@ref(HydroModels_PhysicalModels) below, we are going to show how to then use the data retrieved and prepared in RS MINERVE for numerical water balance modeling, streamflow routing and forecasting.

\TODO: Maybe a good idea would be not to spend too much time on all of this GIS work and provide the relevant GIS raster and shapefiles upfront to the students and then just walk them through how to do this. Otherwise, this ends up being a GIS course in itself.

## Geospatial Data {#GeospatialData}

### Catchment Delineation {#CatchmentDelineation}

Catchment delineation is the first step in geospatial analysis[^pii_retrieval_analysis_geo_hydro_data-1]. This is a step-by-sep guide on how to setup, access, organize and analyze the relevant geo-spatial data for the Chirchik River basin. It is important to mention that this workflow can be utilized in any other catchment.

[^pii_retrieval_analysis_geo_hydro_data-1]: Here, we largely follow a blog post by Craig Dsouza where the process of catchment delineation is nicely described (see this [link](https://craigdsouza.github.io/blog/Watershed-Delineation-QGIS-1){target="_blank"} for more information)

**STEP 1 Open Empty QGIS Project**

Open an empty QGIS Project and set Project Coordinate Reference System (CRS) to EPSG: 32642, WGS84 / UTM 42N (see Figure \@ref(fig:settingCRS)). Map projections try to portray the surface of the earth, or a portion of the earth, on a flat piece of paper or computer screen. In layman's term, map projections try to transform the earth from its spherical shape (three-dimensional or 3D) to a planar shape (two-dimensional or 2D). A CRS then defines how the 2D, projected map in your GIS relates to real places on the earth. Generally, the decision of which map projection and CRS to use depends on the regional extent of the area you want to work in, on the analysis you want to do, and often also on the availability of data.

```{r settingCRS, echo = FALSE, fig.cap = 'Setting the CRS of the Project to EPSG: 32642, WGS84 / UTM 42N.'}
knitr::include_graphics('_bookdown_files/Chap7-Figures/fig_SettingCRS.png')
```

As mentioned above, for the Chirchik River basin case study, we use the CRS EPSG: 32642, WGS84 / UTM 42N. The UTM CRS, where UTM stands for Universal Transverse Mercator, has its origin on the equator at a specific longitude. The Y-values increase southwards and the X-values increase to the West. The UTM CRS is a global map projection and is generally used all over the world. For accuracy reasons and to avoid too much distortion, the world is divided into 60 equal zones that are all 6 degrees wide in longitude from East to West. The UTM zones are numbered 1 to 60, starting at the anti-meridian (zone 1 at 180 degrees West longitude) and progressing East back to the antemeridian (zone 60 at 180 degrees East longitude). Figure \@ref(fig:settingCRS) shows a global map of UTM zones.

```{r UTMZones, echo = FALSE, fig.cap = 'Global map of UTM zones. See [QGIS online documentation](https://docs.qgis.org/3.10/en/docs/user_manual/){target="blank"} for more information.'}
knitr::include_graphics('_bookdown_files/Chap7-Figures/fig_UTmZones.png')
```

When working on a particular catchment in any region on the planet, the corresponding UTM zone should be chosen.

**STEP 2 Adding Groups for Project Structuring**

It is important to keep your geospatial data properly organized. This can be achieved by using Groups in QGIS. You should follow this recommendation and now create the following groups in the Layers Panel: RIVERS, GAUGES, BASINS, DEM, POLITICAL and Temporary[^pii_retrieval_analysis_geo_hydro_data-2]. Once you start to generate a large number of raster and vector layers, these can be conveniently organized within these Groups which act in a similar way as electronic folders on your desktop (see Figure \@ref(fig:LayersGrouping) for an example).

[^pii_retrieval_analysis_geo_hydro_data-2]: Of course, this grouping is just a suggestion and the user is free to organize spatial assets according to his/her own liking

```{r LayersGrouping, echo = FALSE, fig.cap = 'Background map showing the area of interest. Note the Layers grouping in the panel on the left side. The contents in the folder show the geospatial assets that will be created as part of this tutorial.'}
knitr::include_graphics('_bookdown_files/Chap7-Figures/fig_LayersGrouping.png')
```

**STEP 3 Background Map via QuickMapServices and Political Boundaries**

From the main menu, select Web/QuickMapServices/Google/Google Satellite or any other suitable map of your choice. If the QuickMapServices are not available by default, you have to install the corresponding plugin. More information can be found [here](https://docs.qgis.org/3.10/en/docs/training_manual/qgis_plugins/plugin_examples.html){target="_blank"}. If by default the Google Map Service is not available, you can install the plugin HCMGIS via the [**Manage and Install Plugins**]{style="color: blue;"} Menu and then access the Google base Maps via the newly appeared **HCMGIS/BaseMap/** Menu.

Once the background map is visible as shown in Figure \@ref(fig:LayersGrouping), you can zoom in on the area of interest, i.e., the mountain range north-east of Tashkent at the western end of the Tien Shan mountains, where the Chirchik River originates from its tributaries.

For the political shapefiles, we download the relevant country-level data from the [GADM database](https://gadm.org/download_country_v3.html){target="_blank"}. GADM provides spatial data for all countries and their first- and second-level subdivisions in shapefile format. It is advisable to download all first-level administrative country border data for the Central Asian Republics. Finally, make sure that you import the correct shapefile data into the corresponding group, i.e. POLITICAL, in the QGIS Folder.

**STEP 4 Download the Digital Elevation Model (DEM) and Administrative Country Shapefiles**

As a next step, select first the DEM Group in the Layers Panel on the left and then load the SRTM Downloader QGIS Plugin. Zoom in on the region of interest including and up to the point where the Chirchik joins the Syr Darya towards the southwest. Open the plugin and then select Set Canvas Extent. Like this, the coordinates of the AoI get automatically filled in.

If you press 'Download', all the relevant SRTM tiles get downloaded. But first, the plug-in requests you to enter your username and password of your Earthdata login[^pii_retrieval_analysis_geo_hydro_data-3]. The download progress of the individual DEM tiles can be checked in the individual asset progress bars of the SRTM Downloader plugin. As these tiles are only temporary data, there is no need to specify an explicit Output-Path (unless you want to store them for later use in which case you should choose a dedicated output path).

[^pii_retrieval_analysis_geo_hydro_data-3]: If you do not have a login, you can create one at (<https://urs.earthdata.nasa.gov//users/new>){target="\_blank"}

After the download, these individual raster tiles should be merged. Select them all in a first step and then merge them with the menu option [**Raster / Miscellaneous / Merge**]{style="color: blue;"}. An important remark is that after merging, the individual tiles can be deleted to safe disk space. Use the [**Mouse Right Click / Remove Layers**]{style="color: blue;"} option to do so.

To check if all went well, the resulting DEM needs to be recolored. This can be achieved through right clicking on the merged DEM and selecting [**Properties / Symbology**]{style="color: blue;"}. In the Layer Properties Dialogue Box, the Singleband Pseudocolor option should be selected and then a new Colormap created from the catalogue 'cpt-city'. You can then choose any colormap that is suitable for topography coloring. One good choice is for example *wiki-schwarzwald-cont*.

Finally, you have to reproject the DEM to the selected CRS EPSG:32642.

**STEP 5 Cutting the Area of Interest (AoI), DEM Resampling and Filling Sinks**

The downloaded DEM file is very likely much too big and it would be great to cut it to the rough shape that we are focussing on. We just have to ensure that all of our suspected catchment area is inside the cut out. For this purpose, we add a new shapefile Layer and make sure that its Geometry Type is correctly selected as 'Polygon'. Ensure also, that after the creation of the layer, it again is in a Projected CRS (UTM 42N). We can then toggle editing and use the polygon creation and edit tool to roughly outline the basin (AoI) that we are focussing on.

In order to roughly cutout the AoI, select [**Extraction / Clip Raster by Mask Layer**]{style="color: blue;"} and select the corresponding layers in the user dialog box.

```{r LayersCutting, echo = FALSE, fig.cap = 'After'}
knitr::include_graphics('_bookdown_files/Chap7-Figures/fig_LayersGrouping.png')
```

Checking the resolution of the downloaded SRTM DEM, we see that cell sizes are roughly 25 meters [m] in horizontal and vertical direction. For larger catchments, it is advisable to resample the DEM to a coarser resolution. There are many ways to do this in QGIS. Here, it is proposed to use the `r.resample.stats` algorithm so as to decrease the resolution from 25 m to 100 m for later processing.

Next, one has to ensure that sinks in the DEM are filled. First, use `r.fill.dir` to fill potential DEM gaps. The algorithm can be found in the Toolbox section once it is enabled in the dropdown menu Processing. Second, use `r.watershed` to generate the drainage direction and flow accumulation rasters. Note, it is important to specify a 'Minimum size of exterior watershed basin' (take 100'000) and also check the option 'Use positive flow accumulation even for likely underestimates'. As both, the drainage direction and flow accumulation rasters can be reused later, they should be permanently stored on disk, i.e. in the RIVERS group.

**STEP 6 Basin Delineation**

Once we have produced these rasters as described in **STEP 5**, we load the gauging stations if they are available as shapefiles. For each gauging station, we make sure that the gauge lies at the correct location by overlaying it with the Flow Accumulation Raster Data. If this is not the case, we need to relocate individual gauges so that they are at the correct location. This step is important so as to properly delineate the upstream area of a particular gauge under consideration.

If gauges are not available as shapefiles, we can easily add a new shapefile layer and then define one or more gauges in that layer for which we want to delineate basin shapes. Ordered by their 5-digit code as administered by the Uzbek Hydrometeorological Service, the important gauges to consider are:

-   id = 16275, name = Chinaz Gauge, river Chirchik River, lat = 4'528'236, lon = 479'463
-   id = 16279, name = Khudaydod Gauge, river = Chatkal River, lat = 4'596'628, lon = 598'278
-   id = 16290, name = Mullala Gauge, river = Pskem River, lat = 597'351, lon = 4'622'724
-   id = 16294, name = Virtual Gauge, river = Inflow to Charvak Reservoir, lat = 584'616, lon = 4'609'108
-   id = 16298, name = Sidhzak Gauge, river = Nauvalisoy River, lat = 4'618'690, lon = 589'674
-   id = 16300, name = Khodizhkent Gauge, river = Ugam River, lat = 4'610'070, lon = 578'612

Finally, with the algorithm `r.water.outlet`, and by using the Drainage Direction Map, we map those basins and get individual basin raster maps. To distinguish between the zone of runoff formation and the zone of water distribution and consumption in the larger catchment, we propose to use an artificial Gauge just below the Charvak Reservoir dam to delineate the upstream area and to then use the Geoprocessing Tool `Union` to merge these two polygons of upstream dam area and Ugam subcatchment into one zone of runoff formation.

In principle, we are now ready to build a first rough model that does not rely on further reinfinement of the individual subcatchments.

**STEP 7 RIVER DELINEATION (OPTIONAL)**

This step is not strictly required but is simply used to define the topology of the rivers and tributaries properly. However and together with the other relevant layers, the resulting rivers shapefile can be used in the GIS Section of RS MINERVE for modeling. It can be generated easily by selecting the Flow Accumulation raster and the using the raster calculator to generate a binary 0/1 raster for the major stream segments only[^pii_retrieval_analysis_geo_hydro_data-4]. While you can experiment with arbitrary cutoff levels, a good value is 10'000. Hence, the raster calculator command to apply is `( @FlowAccumulation > 10000 )` under the assumption that your flow accumulation layer is named accordingly. The resulting raster can finally be vectorized to arrive at the river network.

[^pii_retrieval_analysis_geo_hydro_data-4]: Remember, the flow accumulation matrix entries correspond to the accumulated number of cells flowing into that particular cell (assuming equal weights for the calculation)

It is advisable to perform a `Vector Geometry / Fix Geometries` correction on the resulting vector layer as there are likely self-intersections the processing of the layer. Once this is done, the layer can be clipped to the basin extent should this still be required.

**STEP 8 POLYGONIZATION OF SUBCATCHMENTS**

The rainfall-runoff model that we are using accounts for runoff generation processes in different contributing subcatchments. Depending on the average altitude of these, the timing and magnitude of snow- and glacier-melt contributions might highly vary throughout a hydrological year. The same is true within these individual contributing subcatchments where snow melt in lower elevations starts earlier than at higher elevations due to the negative temperature lapse rate. To account for these *phased in time* processes, the subcatchments can be discretized into elevation bands of a typical width. A sensible choice in the context of the Chirchik River Basin is to use elevation bands of 500 meters spacing and then model the relevant processes for each of these bands as if they were individual contributing smaller separate sub-subcatchments that dewater all to the same place.

With the QGIS raster to vector option, we polygonize the basins. Check the validity of the polygon with Vector Geometry/Check Validity and correct, where necessary.

### Computation of Elevation Bands

With the reclassification algorithm, we create elevation band polygons based on the DEM layer. First, we smooth the DEM to simplify the elevation bands a bit. Then, we Reclassify by Table the DEM into the desired elevation bands. For the exercise here and given the specific topography of the basin(s) that we are interested in our Case Study, we enter manually altitude bands that are 500 meters apart (see Figure \@ref{fig:ReclassificationByTable}). As output, we get a raster map with the individual elevation classes. The prepared DEM elevation levels range from 0 masl to 4'176 masl over the whole catchment. From the

```{r ReclassificationByTable, echo = FALSE, fig.cap = 'Reclassifying a DEM to make elevation classes that cover a range of 500 meters.'}
knitr::include_graphics('_bookdown_files/Chap7-Figures/fig_ReclassificationByTable.png')
```

Using the elevation band raster map, we use GDAL / Raster Conversion / Polygonize to create the elevation band polygons.

Polygon clipping with SAGA/Vector Polygon Tool/Polygon Clipping tool to arrive and subcatchment level basins with altitude bands.

Now, we have derived the required shapefiles. For importing into the rainfall-runoff model in RS MINERVE, we have to now properly prepare their attribute tables. This is a somewhat lengthy and tedious process but will help later greatly in terms of automatic model creation in RS MINERVE.

RS Minerve requires the following GIS layers for the automatic translation into a rainfall-runoff model, i.e. subbasins.shp, junctions.shp and rivers.shp (see [@rsminerve_um] for more details).

The individual feature attributes should be added either at the time of the layer creation or with the field calculator in QGIS.

```{r RSMINERVE_GIS, echo = FALSE, fig.cap = 'Default Shapefile layers required in RS MINERVE to simplify the model topology building. See [@rsminerve_um] for more information.'}
knitr::include_graphics('_bookdown_files/Chap7-Figures/fig_RSMINERVE_GIS_Files.png')
```

//FIXME: Check what to do with this! We note that for water supplies in the rainfall/runoff model, the focus is on the zone of runoff formation.

//TODO: Add GLIMS global land ice data.

**STEP 9 INTEGRATION OF GLACIER DATA**

For the retrieval of data on land ice, we will utilize GLIMS data.

## Climate Data

This Section requires the following R packages to be installed. If you are running R in RStudio and some of the packages are not yet installed on your computer, RStudio will warn you and ask, whether you want to have them installed.

//TODO: Suppress output below

```{r codeLoad, echo=TRUE, eval = TRUE}
# Tidyverse 
library(tidyverse)

# File navigation
library(here)

# Copernicus Climate Data Store
library(ecmwfr)
library(keyring)

# Handling netcdf files
library(ncdf4)

# Spatial data plotting & plotting
library(rgdal)
library(raster)
library(rgeos)
library(sp)
library(sf)
library(rasterVis)
library(RColorBrewer)
```

### Access, Select and Download ERA5 Reanalysis Data

For the climate data to be used in the modeling approach, we use ERA5 data from the European Center for Medium-Range Weather Forecasts (ECMWF, \<www.ecmwf.int\>). ERA5, the successor to ERA-Interim, provides global, hourly estimates of atmospheric variables, at a horizontal resolution of 31 km and 137 vertical levels from the surface to 0.01 hPa [@era5-desc]. ERA5 presently extends back to 1979 but will ultimately be extended back to 1950[^pii_retrieval_analysis_geo_hydro_data-5].

[^pii_retrieval_analysis_geo_hydro_data-5]: Although this is an extraordinary product, users still need to be aware of the limitations of reanalysis; two of the major ones are that non-physical trends and variability may be present in the record due to changes in the observing system, and that the climatologies of some variables, like surface energy fluxes, are not well represented.

The ERA5 data is available via the Copernicus Climate Store at <https://cds.climate.copernicus.eu>. However, before we can access, select and download it there, each user has to register with a personal account in the store. For this purpose, the user should navigate to the website and register via the Login/Register/NewAccount Menu. You will receive an email once your account is ready.

Log in to your account and go to your user profile where you find your user ID and API key. The relevant information should be copied and into the relevant places of the code chunk below and then be executed.

```{r,eval=FALSE}
#Note: replace the UID and key strings below with the proper user's information in your Copernicus Climate Data Store account.
UID <- 'UID'
API_key <- 'key'
#This function links your password and user id for later steps
wf_set_key(UID, API_key, 'cds')
```

//TODO: output still showing. How to deal with it?

```{r ecmf_real_register, echo = FALSE, message = FALSE}
#Note: replace these strings with the information in your Copernicus Climate Data Store account
UID <- '11732'
API_key <- '9b6f4531-b1f0-4005-82e5-afa48aabd3e2'
#This function links your password and user id for later steps
wf_set_key(UID, API_key, 'cds')
```

If all worked well, you will get the following confirmation in the console:

```{r <chunk-label>, echo = TRUE,eval=FALSE}
## User UID for cds service added successfully
```

On the Copernicus website, make sure that you are logged into your account and the navigate to Datasets. There, search for the Product 'ERA5-Land monthly averaged data from 1981 to present' and select it[^pii_retrieval_analysis_geo_hydro_data-6]. You end up on the products homepage where you can get more information and download the data via a form where you select the product's type, variables, the years, months and time of day, the geographical area and, finally, the download file format of interest. Please select the following:

[^pii_retrieval_analysis_geo_hydro_data-6]: The direct link is <https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land-monthly-means?tab=form>.

-   Product type: Monthly averaged reanalysis

-   Variable:

    -   Temperature: 2 m Temperature
    -   Lakes: NA
    -   Snow: NA
    -   Soil Water: NA
    -   Radiation and Heat: NA
    -   Evaporation and Runoff: Potential evaporation
    -   Wind, Pressure and Precipitation: Total precipitation
    -   Vegetation: NA

-   Year: Select all

-   Month: Select all

-   Time: 00:00

-   Geographical area: Sub-region extraction (West = 65, East = 80, South = 35, North = 45)

-   Format: NetCDF (experimental)

Accept the Terms of use and press the 'Show API request button'. You should see the following Python request now as shown in Figure \@ref(fig:Copernicus-API-Request).

```{r Copernicus-API-Request, echo = FALSE, fig.cap = 'Screenshot showing the Copernicus Data Store API request that can be copied and posted into RStudio for the convenient download of the data there.'}
knitr::include_graphics('_bookdown_files/Chap4-Figures/fig_Copernicus_API_request')
```

The request should be copied and pasted into RStudio into your current .Rmd file there. Select the python request with the cursor and choose 'ECMWFR/Python to List' under the Addins Menu. The python request will then automatically be translated into a an r command. Please check that everything is ok by comparing it with a correct request as shown below. Also, please note that we have changed the target file name by specifying `target = reanalysis-era5-land-monthly-means_CentralAsia.nc`.

In a final step, the user can then download the data with the `wf_request()` function.

```{r ERA5-request, echo = TRUE, eval = FALSE}
# Here is is the resulting request in R language 
request <- list("dataset_short_name" = "reanalysis-era5-land-monthly-means",
  format = "netcdf",
  product_type = "monthly_averaged_reanalysis",
  variable = c('2m_temperature', 'potential_evaporation', 'total_precipitation'),
  year =  c('1981', '1982', '1983',
            '1984', '1985', '1986',
            '1987', '1988', '1989',
            '1990', '1991', '1992',
            '1993', '1994', '1995',
            '1996', '1997', '1998',
            '1999', '2000', '2001',
            '2002', '2003', '2004',
            '2005', '2006', '2007',
            '2008', '2009', '2010',
            '2011', '2012', '2013',
            '2014', '2015', '2016',
            '2017', '2018', '2019',
            '2020'),
  month = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12"),
  time = "00:00",
  area = "45/65/35/80",
  #dataset = "reanalysis-era5-land-monthly-means",
  target = "reanalysis-era5-land-monthly-means_CentralAsia.nc"
)

# Download data as netcdf file and store it in the directory where you are running this script, this returns the path to the file 
ncfilelink <- wf_request(user = UID,
                     request = request,
                     transfer = TRUE,
                     path = here(),
                     verbose = TRUE)
```

```{r, echo = FALSE, eval = TRUE, results = 'hide', warning = FALSE, message = FALSE}
# Here is is the resulting request in R language 
request <- list("dataset_short_name" = "reanalysis-era5-land-monthly-means",
  format = "netcdf",
  product_type = "monthly_averaged_reanalysis",
  variable = c('2m_temperature', 'potential_evaporation', 'total_precipitation'),
  year =  c('1981', '1982', '1983',
            '1984', '1985', '1986',
            '1987', '1988', '1989',
            '1990', '1991', '1992',
            '1993', '1994', '1995',
            '1996', '1997', '1998',
            '1999', '2000', '2001',
            '2002', '2003', '2004',
            '2005', '2006', '2007',
            '2008', '2009', '2010',
            '2011', '2012', '2013',
            '2014', '2015', '2016',
            '2017', '2018', '2019',
            '2020'),
  month = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12"),
  time = "00:00",
  area = "45/65/35/80",
  #dataset = "reanalysis-era5-land-monthly-means",
  target = "reanalysis-era5-land-monthly-means_CentralAsia.nc"
)

# Download data as netcdf file and store it in the directory where you are running this script, this returns the path to the file 
ncfilelink <- wf_request(user = UID,
                     request = request,
                     transfer = TRUE,
                     path = here(),
                     verbose = TRUE)
```

```{r , eval = TRUE, echo=FALSE, results = 'show'}
print('moved temporary file to -> /.../reanalysis-era5-land-monthly-means_CentralAsia.nc')
print('request purged from queue!')
```

Some Sources on NetCDF and raster files: Here are some good resources to get you started: <https://pjbartlein.github.io/REarthSysSci/index.html> and <https://cmerow.github.io/RDataScience/05_Raster.html>.

## Hydrological Data

//TODO: Show added value from consulting data from altimetry <https://dahiti.dgfi.tum.de/en/map/>

Maybe show some analysis in KNMI CLimateExplorer?
