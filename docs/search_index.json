[["index.html", "Applied Modeling of Hydrological Systems in Central Asia Welcome", " Applied Modeling of Hydrological Systems in Central Asia Tobias Siegfried 2021-02-16 Welcome Welcome to the online course book on Central Asian hydrology and the mathematical modeling of the hydrological systems there. The book is dedicated to the young and aspiring water professionals of the region. The book adopts an open-source philosophy and promotes the use of open-source data and software. The online version is hosted at https://tobiassiegfried.github.io/Applied_Hydrological_Modeling_Bookdown/, maintained via GitHub and currently work in progress. "],["Preface.html", "Preface", " Preface This handbook is geared towards young water professionals in Central Asia. As they now graduate, they inherit an extraordinarily complex system of man made irrigation and hydropower infrastructure that is gradually aging. At the same time, they enter a sector that has enabled the region to prosper and flourish over hundreds if not thousands of years. Finally, they face work where opportunities for modernization abound after decades of inadequate investments. It is the hope of the author that this text provides a source of inspiration for this target group and that the text and the methods presented will also be used by teachers and in university curriculae locally. The author is grateful for the support by the Global Water Programme at the Swiss Agency for Development and Cooperation and especially to Stephanie Piers de Raveschroot and Andre Wehrli there. The author owes a lot to Andrey Yakovlev who provided invaluable guidance throughout his professional career. Finally, this book is dedicated to our past, current and future colleagues at the Central Asian Hydrometeorological Agencies whose tireless work in collecting and analyzing hydro-meteorological data in Central Asia has helped to greatly improve our understanding of the complex runoff generation processes at work in the region. Tobias Siegfried Zurich, February 2021 "],["Foreword.html", "Foreword", " Foreword Oasis between Samarkand and Buchara. Source: Tobias Siegfried. This is a online book about applied hydrological modeling. It is geared towards students and young professionals in Central Asia who are interested in learning modern modeling approaches. The book teaches by examples and uses two catchments from the Syr Darya and Amu Darya river basins as case studies. While the presented case studies are exclusively from Central Asia, the methods demonstrated can be applied elsewhere. First, key hydro-climatological characteristics of the region are presented. This Section draws heavily on Victor Shults’ “Rivers of Middle Asia” and presents relevant materials from this famous book in a modern way. Two hydrological basins are further highlighted in in-depth case studies, i.e. the Gunt River in the Amu Darya catchment and the Chirchik river basin as the biggest right tributary to Syr Darya. The analyses of these catchments draws on available data from the Central Asian Hydrometeorological Services. The analysis of the available hydro-meteorological data uses different types of methods implemented in R which is a programming language widely used in data analysis and mining (R Core Team 2013). Three different types of modeling approaches are demonstrated and discussed in greater depth. First, long-term water balance modeling using the Budyko framework is introduced to discuss and demonstrate the quantification of climate change impacts on hydrological systems in Central Asia. Using this type of model, the effects of climate change on the long-term water balance are discussed for the Gunt River. The Gunt river is one of the key right tributaries to the Pjandz, i.e. the upstream Amu Darya, and emerges at high altitudes in the eastern Pamirs. Second, a more detailed modeling approach using semi-distributed, lumped, conceptual hydrologic-hydraulic modeling will be used to demonstrate how intra-annual changes due to climate forcing and changes therein can be quantified. These approaches will be demonstrated again for the Gunt catchment and also for the Chirchik river basin and its tributaries. Furthermore, the use of these models to study different kinds of reservoir operations will be presented and impact on hydropower production as well as on downstream water availability discussed. Third and finally, empirical modeling will be introduced for forecasting. These types of models are currently utilized in the Hydrometeorological Agencies of the region for forecasting discharge at different lead times, ranging from one day ahead up to seasonal forecasts. These models use long term time series to learn relationships between past, observed quantities and future system responses. With everything that is presented, the focus is on the use of open source and free software. For data preparation and analysis as well as for water balance and empirical modeling, R and RStudio are utilized (R Core Team 2013; Team’ 2020). For the processing of geographic data, workflows in QGIS are demonstrated (QGIS Development Team 2021). For hydrological-hydraulic modeling, the free RSMinerve is utilized which is a environment for the modeling of free surface runoff flow formation and propagation (Foehn et al. 2020; Garcia Hernandez et al. 2020). "],["ShortHistory.html", "Chapter 1 Short History of Water in Central Asia", " Chapter 1 Short History of Water in Central Asia Still from a propaganda film documenting the construction of the Big Fergana Canal. The canal was constructed in 1939 constructed over a period of 45 days and a length of approx. 280 km through the use of 180’000 forced labor. This Chapter provides a short introduction to the region of how man has tamed and allocated the Central Asian water resources. It draws on texts from an emerging field of the study of colonial times in the region and how the Zarist and Russian conquests effectuated dramatic changes in the use and allocation of water resources. These changes, however, as is becoming more and more clear thanks to recent research, were built on top of a system of traditions, some of which were developed over the course of centuries, and neither able to complete replace them nor root them out. The clash of tradition with modernity continues to this day and is the cause of renewed attention of governments and the international community alike as environmental degradation directly linked to the ineffective and unustainable use of water grows in extent. "],["TamingHydrologicalSystems.html", "1.1 The Taming of the Central Asian Rivers", " 1.1 The Taming of the Central Asian Rivers The conquest of nature, as per the thinking of the Russian government in the late 19th century, was an essential precondition of successful colonial policy. It enabled the economic appropriation of new territories and facilitated the development of administration and the integration of local authorities into the colonial system (Pravilova 2009). "],["PostTransitionDevelopmentsChallenges.html", "1.2 Post-Transition Development and Challenges", " 1.2 Post-Transition Development and Challenges Political Changes: Waking up to a new Reality and Adverse Developments "],["HydrologicalSystems.html", "Chapter 2 Hydrological Systems in Central Asia", " Chapter 2 Hydrological Systems in Central Asia Caution! - Work in progress. Upstream Naryn, Kyrgyzstan. Source: Tobias Siegfried. "],["regional-hydro-climatological-features.html", "2.1 Regional Hydro-Climatological Features", " 2.1 Regional Hydro-Climatological Features The inhomogeneity of the relief structure causes Central Asia to be the territory of immense contrasts. Here, extreme aridity in the hot deserts of the plains and, only 100 km away, abundant humidity and snowfields in the mountains where precipitation levels can range between 1’000 mm up to 2’000 mm. The uneven distribution of water bodies is striking. The mountains of Central Asia are riddled with an extremely branched river network consisting of more than ten thousand watercourses. In the flat foothill areas surrounding the mountain ranges, another branching river network is found which consists of irrigation channels, which do not contribute to the runoff of the core rivers, but rather divert the water from the river network and diffuse it in the irrigated oases where much of it gets evapotranspirated. Central Asia is spreading over approximately 4 million km2, including the territories of Kazakhstan, Kyrgyzstan, Tajikistan, Turkmenistan and Uzbekistan (Central Intelligence Agency, n.d.). In the vast plains that cover around 70% of the total territory, there are only very few rivers which have scarcely any tributaries from the point they leave the mountain areas all the way to their mouth. Abundant solar radiation, high temperatures, small amounts of precipitation, a lack of humidity, unstable snow cover, slight slopes, geological structures1, etc., hinder the formation of surface flows in the plains of Central Asia, despite their big importance for the local agricultural production there. Only the largest rivers, such as Syr Darya, Amu Darya, and Ili are able to survive hundreds of kilometers of deserts and reach the most important landlocked reservoirs – the Aral Sea and Lake Balkhash (Shults 1965). Figure 2.1 shows an overview of the region. Figure 2.1: Map highlighting the Central Asian rivers network (rivers are shown in blue color). The dense river network in the mountainous areas starkly contrasts with the sparse one in the plains. Source: Zoï Environment Network. All Central Asian river basins are endorheic with no water draining out of the region but only evaporating back to the atmosphere. This emphasizes the importance of moisture transfer as an important mechanism in the region region since the formation of substantial watercourses in the mountains is followed by their complete dissipation in the plains, including in the irrigated oases and the terminal lakes, i.e. the Aral Sea and Lake Balkash. In the boreal summer, tropical air masses form in the plains of Central Asia. At that time, even cold air masses coming from the north heat quickly. There is no possibility for temperature differences between the lower and the middle troposphere to occur which explains the horizontal uniformity of high temperatures during summer. Contrary to this, the temperature differences in the region are highest in January during the peak of the boreal winter. As the territory of Central Asia is unprotected from the north, it is under the influence of dry, exceptionally cold air masses originating from the Arctic region and Siberia. These air masses can cause sharp frosts. The further the Siberian or Arctic air masses penetrate towards the west and the south, the more their temperature increase. This explains the big difference in air temperatures during winter between the north and the south of Central Asia. Cold air intrusions are often accompanied by the influx of warm air from the tropics. The cold waves taking turns with hot air masses cause unsteady frost in the plains and, together with generally low precipitation values, do not allow for the formation of a significant snow pack there (Shults 1965). //TODO: properly reference Section here. As is discussed further below, the winter snow cover in the high mountain ranges plays an essential role in runoff formation in the spring and summer months and is thus of key relevant to irrigation agriculture in the downstream and for hydropower production (see Section~ below). Understanding the atmospheric mechanisms resulting in favorable conditions for winter precipitation is thus essential. With a warming climate and the associated increase of evapotranspiration in the downstream plains and the loss of glacier storage in the mountainous areas, a solid understanding of snow pack formation becomes even more pertinent. (Gerlitz et al. 2018) discusses how the position of the westerly jet stream is connected with the frontal trajectories and the westerly disturbances which are the main moisture sources if the region. The relative position of these planetary wave tracks and their associated westerly flows to the orographic mountain barriers plays thus a key role. The main precipitation events migrate over the winter season from south to north. The southern parts of central Asia, particularly the windward slopes of the Karakorum and Hindu Kush mountain ranges, receive high amounts of winter precipitation (December-January-February), which reaches up to 60% of the total annual precipitation. During spring the zone of maximum precipitation migrates northward, reaches the Pamir plateau in March, and continues to Tien Shan in April/May. The interaction of tropical air masses from the Arabian Golf with westerly flow in Central Asia is another important moisture source for the region. Using data of the ERA-Interim reanalysis, (Gerlitz et al. 2018) classifies 8 weather types (WT) based on typical regional pressure field patterns over a domain covering 20- 60N and 50- 90E. Like this, large-scale features of winter circulation patterns in Central Asia can be captured. WT are analyzed with regard to the spatial anomalies of temperature and precipitation. Figures 2.2 and 2.3 show results. In these Figures, the individual plates WT 1 - 8 are labeled according to the main circulation feature over Central Asia, i.e. a Rossby ridge (R) or trough (T). Generally, it can be observed that configurations that are associated with a Rossby trough over Central Asia lead to an intensification of westerly moisture fluxes (WT 3, WT 7, and WT 8). If there is, however, a Rossby ridge type configuration as shown in WT 1, WT 2, and WT 4 panels of Figures 2.2 and 2.3, moisture fluxes are northward-shifted and precipitation suppressed (Gerlitz et al. 2018). Figure 2.2: Composite maps illustrating the averaged anomalies of ERA-Interim/Land 6-hourly temperature for each weather type (WT 1 - WT 8). Values are depicted in standard deviations for each grid cell, respectively. Arrows indicate anomalies of the 500-hPa ERA-Interim wind field (Gerlitz et al. 2018). Figure 2.3: Composite maps illustrating the averaged anomalies of ERA-Interim/Land 6-hourly precipitation sums for each weather type. Values are depicted relative to the seasonal mean 6-hourly precipitation sum ((100)-1) for each grid cell, respectively. Arrows indicate anomalies of vertically integrated moisture fluxes (Gerlitz et al. 2018). Precipitation is extremely unevenly distributed in the region. 20% of the plain area receives less than 100 mm, while 91% of the territory receives less than 300 mm of precipitation a year with an overall average of 173 mm. The mountains are thus an important climatological and hydrological factor, since they are the places where the water condensates and where the rivers and groundwater originate. Although the range of precipitation levels is wide (60 mm - 2’500 mm), the mountains receive on average more than three times more precipitation than the plains, and the low temperatures favor its accumulation in the solid state (Shults 1965). The influence of the relief is notable also when speaking of precipitation distribution during the year. The high ground areas in Central Asia are witnessing an almost even distribution of precipitation on monthly basis, whereas at the same time, in the inner parts of high mountain ridges there is more precipitation in summer. Such a distribution of precipitation in the inner parts of mountain ridges is a consequence of high condensation levels in summer due to intense evaporation taking place in snow melting areas or, less often, on water surfaces. A typical example showing the influence of the local water vapor emission on annual distribution of precipitation could be the Issyk Kul Lake Basin. There the percentage of precipitation received during summer and the second half of spring, so from May to August, is sometimes reaching even 80% of the total annual precipitation amount, all thanks to the evaporation of the water from the lake and the emergence of thermal convection and subsequent moisture recycling. The areas that are characterized by a predominant precipitation during summertime are the Central Tian Shan and Eastern Pamir, where the difference between the summer and the rest of the year is so big that during summer 60% of all annual precipitation is received. The predominance of the precipitation during summer in case of mountains with steep slopes (15° - 30°) causes fast and abundant snowmelt runoff which is directed to the lower areas and then turns into a river network. Thanks to a large amount of precipitation, relatively low evaporation levels and steep slopes, all rivers of Central Asia, including the largest ones such as Amu Daria, Syr Daria, Ili or Zeravshan, arise in the mountains. Arising in the high ground area, these rivers are mainly fed by snow, glaciers and snow patches melting, as well as by groundwater that, again, were all formed by the same sources. Due to the presence of the vertical thermal gradient, the start of the positive air temperature season, and consequently, the start of the ice and snow melting season does not take place at the same time uniformly. Rather, the snow melting process is of protracted nature and the higher the mountains are in a particular catchment, the later the snow-melt floods take place on rivers that are emerging there. The melting process starts last in the permanent snow and glaciers regions. Because of this, the rivers, which are fed by snowmelt in the upper parts of the catchment area, are of great importance for the irrigation of crop fields, since they are characterized by the most significant water runoff during July and August, at which point the irrigated plains experience severe drought and when irrigated crops have the highest water demand. The rivers having this kind of a runoff regime (nivo-glacial) are Pyandzh and Vakhsh Rivers, as well as the ones deriving from them, such as Amu Darya, Chu, Zeravshan, Talas and Ili Rivers with its numerous tributaries. These rivers all feature a small variability of annual runoff. This is partly a result of the regulating effect of the zone of eternal snows and ice and is very important from the perspective of agricultural production in the downstream. These rivers are thus particularly valuable, not only for irrigation but also as a source of hydroelectric power. Rivers originating from the low mountains but being fed mainly by the snowmelt (nival regime rivers), are characterized by the early floods (March-May) and a sharp variability of annual runoff, since the amount of water is almost entirely determined by the snow reserves in the mountains which were accumulated in the previous winter season. Finally, the watercourses originating from the lowest parts of mountains or from low mountains, (nivo-pluvial regime rivers), which in comparison to other regimes receive much more liquid precipitation, are characterized by large amounts of water, often saturated by sediment, passing during short periods of time. These are so-called mudflows. These watercourses often dry up during summer because of a decrease in supplies from groundwater. When entering the plains, the rivers of Central Asia form wide-spreading alluvial fans consisting of materials brought by them from the mountains. Here the rivers are usually divided into several channels, and a large part of water is filtered by these sediments. The large quantities of groundwater in these alluvial fans, which appear due to this process, mostly protrude from the earth surface at the edges these alluvial fans, causing the small rivers that are fed by groundwater, so-called Karasu rivers, to emerge, which are also used for irrigation. The relief thus has an extremely strong and many-sided impact on runoff formation processes. This influence is mediated through climatic factors, on which the recharge of the rivers, as well as the processes of thawing of snow and ice, etc., depend. In this regard, both the average water content, consistency of the annual runoff and its distribution over a year, as well as other characteristics of the river runoff cannot be considered independently from key relief factors, first and foremost altitude. All this demands a careful and comprehensive analysis of the impact of the relief on runoff processes. namely the distribution of sand and loess relief types, where the former are more permeable and the latter contain more moisture↩︎ "],["chap-regionalWaterBalance.html", "2.2 Regional Water Balance", " 2.2 Regional Water Balance It is instructive to show the opposite hydrological functions of mountain versus flat areas of Central Asia by means of simple water balance considerations. The water balance equation for mountain area, broadly defined, can be written as follows: \\[\\begin{equation} \\tag{2.1} p = e + q_{s} + q_{g} \\end{equation}\\] whereby \\(p\\) represents the average long-term amount of precipitation and condensation of water vapor from the atmosphere, \\(e\\) the average long-term evaporation, \\(q_{s}\\) the average long-term surface outflow and \\(q_{g}\\) the average outflow of groundwater. This equation shows that the mountain area receives moisture only from the atmosphere and rainfall which precipitates within its limits and evaporates only partially. The remainder part of it flows down in the form of surface and underground drainage. Sharp partition of a relief in the mountain area, and consequently, a deep natural drainage is the reason why groundwater is almost entirely connected to the river network already in the mountain area. The Meso-Cenozoic deposits, containing waterproof horizons, and the Paleozoic massifs on the border with the flat areas obstruct groundwater flows. Thus, the groundwater inflow to the flat areas makes no more than 10% - 15% of the surface one and therefore it can be neglected in the first equation. Then the water balance equation will have the following appearance: \\[\\begin{equation} \\tag{2.2} p = e + q_{s} \\end{equation}\\] Based on available data, the rate of surface outflow \\(q_{s}\\) can be calculated quite precisely: 155 billion m3 or 201 mm annually. River basin-specific surface runoff values are provided in Table. It is impossible to measure the amount of the accumulated water vapor in the mountains accurately just by observation, so we have to proceed from the rate of the runoff, for which we need to know the value of runoff coefficient. The last can be approximately considered as equal to 0.35 (see also next Section). Then, \\(p\\) equals 575 mm and \\(e\\), as follows, 575 mm - 201 mm = 374 mm. Table 2.1: Key water balance basin statistics of selected large basins in Central Asia. Basin Name Area (km2) Runoff (m3/s) Runoff entering flatlands (m3/s) Runoff Coeff. (l/ (s km2)) Caspian Sea 29’700 22 12 0.74 Endhoreic Basins of TUK and AFG 193’300 180 155 0.93 Amu Darya 227’300 2’500 2’500 11 Syr Darya 150’100 1’200 1’200 8 Chu and Talas River Basin 37’540 190 190 5.1 Lake Issyk Kul 12’600 115 - 9.1 Southern Balkash Lake 119’000 800 800 6.7 Total 769’600 5’007 4’857 6.5 It should be noted that the rate of surface water inflow to the flatlands is smaller than the runoff which is generated in the mountain areas as part of it is utilized in the mountain area for irrigation purposes (the rivers of Turkmenistan are in this regard an especially good example), or it evaporates from a surface like of the Lake Issyk Kul and other smaller lakes. If, from the mountain area, we exclude reservoirs of the river Atrek and the rivers of Turkmenistan and Afghanistan with no runoff which, occupying the big space (29% of all mountain area of Central Asia), excel in a minute quantity of rainfall and exclusively low water levels, separate elements of water balance will be expressed by the following sizes: \\(p\\) = 675 mm , \\(q_{s}\\) = 270 mm and \\(e\\) = 405 mm. In this case, the water balance of mountain area shows its hydrological essence even more clearly. The equation of water balance for the flat area can be written in the form of \\[ p + q_{i} = e \\] where \\(q_{i}\\) represents the surface inflow of water. We neglect underground outflow in the flat area as, even when it takes place, it is absolutely insignificant. The average amount of rainfall calculated by planimetering of the isohyetal map is equal to 173 mm. The rate of inflow of water is equal to the outflow of water from mountain area, i. e. \\(q_{s} = q_{i} = 155 \\cdot 10^{9} \\text{ m} ^{3}\\). After making its way down to the flat area, which includes the surface of the Aral Sea and Lake Balkhash, the surface inflow of the rivers reaches 124 mm and the evaporation is \\(e = p + q_{i} = 173 \\text{ mm} + 124 \\text{ mm} = 297 \\text{ mm}\\). It is noteworthy to mention that from the entire moisture appearing in the flat area, 58% nevertheless is from atmospheric precipitation, despite its rather insignificant absolute amount. Comparing the two water balance equations shows that the mountain areas receive 575 mm of moisture from the atmosphere of which 374 mm evaporates back to the atmosphere and 201 mm reach the downstream flat area in the form of a surface runoff. Conversely to this, the flat areas receive 297 mm of water from direct precipitation and from inflow of mountain runoff. All of this water evaporates back to the atmosphere. To summarize, it is clear that in the area of runoff formation, \\(p&gt;e\\), in the area of runoff losses \\(p&lt;e\\), and that in the area of runoff balance \\(p\\approx e\\). In each area where the runoff processes show the same orientation, its origin, distribution in time and space, and also the intensity of processes can however vary. In this sense, depending mainly on local topography (generally speaking, depending on the altitude, orientation and exposure of a reservoir to humid air masses), the specific runoff, the persistence of the annual runoff and its distribution over a year, as well as other characteristics of the river flow can sharply differ in different parts of the area of runoff formation, as it was already discussed above. On the other hand, the intensity of runoff losses, their distribution over a year, etc. within the area of runoff losses, considerably depend on the economic activities and features of climatic conditions. "],["runoff-formation.html", "2.3 Runoff Formation", " 2.3 Runoff Formation The process of runoff formation is critically determined by the generation of direct runoff from liquid precipitation and the melting of snow and ice over the course of a hydrological year. Considering carefully the individual components for basins under consideration is important in order to properly understand the runoff regimes of individual rivers and for conceptualizing key processes for mathematical modeling. Figure 2.4: Map of the upper Syr Darya and Amu Darya catchments. The catchments are outlined. Colors encode topographic height. Basin outlets (red dots) are chosen to correspond to the confluence of the two main rivers for each catchment. Topographic data is from (“Srtmgl1 n -ASA SRTM Version 3.0” 2020). First, we study the role of glacier melt. For this, it is instructive to start to look at the condition of discharge formation in the Amu Darya and Syr Darya basins (see Figure 2.4). More specifically, we compare the two main subcatchments of the Vakhsh and Pyandzh Rivers in the Amu Darya and the Naryn and Kara Darya catchments in the Syr Darya2. In the first two reservoirs, the mountains exceeding 5’000 m occupy 6.2% of their area, and the mountains higher than 4’000 m — 42%, in case of reservoirs of the second two rivers, the mountains exceeding 5’000 m occupy less than 1% of their area and the ones with altitudes over 4’000 m — only 4%. Figure 2.5 shows the basins’ hypsographic curves. Even if we take into account that in the case of the basins of Pyandzh and Vakhsh the snow line is on average located at the height of 4’600 m — 4’500 m and in case of the basins of Naryn and Kara Darya at 4’000 m - 3’900 m, 19% — 22% of the reservoirs of Pyandzh and Vakhsh is located above the snow line, and in case of reservoirs of Naryn and Kara Darya it is only 4% — 5%. The role of glaciers in the annual distribution of runoff is thus more substantial in the case of the Amu Darya as compared to the Syr Darya. And to come to an informed conclusion, one has to take into account all land ice features, including their altitude. Figure 2.5: Hypsographic curves of the upper Syr Darya and Amu Darya catchments. The SRTM topographic model was used for the calculation of the curves (“Srtmgl1 n -ASA SRTM Version 3.0” 2020). Data on land ice can be obtained from the Global Land Ice Measurements from Space glacier database GLIMS (GLIMS and NSIDC 2005, updated 2018). The Global Land Ice Measurements from Space (GLIMS) project at NSIDC has implemented a database of glacier outlines from around the world and other information about glaciers that includes the metadata on how those outlines were derived. At &lt;www.glims.org&gt;, one can download outlines and metadata for glaciers in a choice of different formats, including KML (for viewing in Google Earth), ESRI shapefiles, GMT (Generic Mapping Tools), MapInfo, or GML (Geography Markup Language). Figure 2.6 shows a sample visualization of the GLIMS data for the zone of runoff formation of the Amu Darya. The data will also be utilized in Chapter (ref?)(#HydrologicalSystems) below to obtain good ideas of the subcatchments’ glaciation levels. Figure 2.6: Visualization of the GLIMS data glaciation in the Vaksh-Pyandzh basin. The light blue shaded polygons show land ice on top of the underlying digital elevation model. Figure 2.7 shows the distribution of mean glacier elevations of the Randolph Glacier Inventory 6.0 dataset in the GLIMS database. The center of mass for the Amu Darya is at 4’827 masl whereas it is at 4’110 masl for the Syr Darya. Figure 2.7: Distribution of mean glacier elevations as extract from the GLIMS database. Only data from the Randolph Glacier Inventory 6.0 was used as subset of the complete GLIMS record. For the computation of the mean elevation, SRTM data was utilized. Since the GLIMS database contains contains the shapes of glaciers as geometric features, we can calculate easily calculate areas that the individual glaciers cover and then utilize scaling relationships between surface area and volume to estimate total ice storage in the individual Central Asian catchments. (Aizen, Aizen, and Kuzmichonok 2007) reports such scaling relationship for the Central Asian region. As a function of glacier area, they are \\[ V = 0.03782 S^{1.23} \\text{ for } S&lt; 0.1 \\text{ km}^2 \\\\ V = \\frac{0.03332 S ^ {1.08} e^{0.1219 L}}{L^{0.08846}} \\text{ for } 0.1 &lt; S &lt; 25 \\text{ km}^2 \\\\ V = 0.01848 S + 0.021875 S^{1.3521} \\text{ for } S &gt; 25 \\text{ km}^2 \\] where \\(S\\) is the area of a glacier, \\(L\\) the length of the glacier and \\(V\\) the computed volume from the scaling relationship. The length \\(L\\) of the individual glaciers can be approximated by subtracting the minimum glacier elevation from the corresponding maximum elevation. Like this, we can compute land ice volumes of the Amu Darya and Syr Darya basins in an approximate yet scientific way. Alternatively, we can use the volume area scaling relationship by Yerashov. (The emerging river after the confluence of the Vakhsh and Pyandzh rivers is called Amu Darya whereas the Syr Darya emerges after the confluence of the Naryn and Kara Darya rivers.)↩︎ "],["average-multi-year-runoff.html", "2.4 Average Multi-Year Runoff", " 2.4 Average Multi-Year Runoff "],["annual-runoff-fluctuations.html", "2.5 Annual Runoff Fluctuations", " 2.5 Annual Runoff Fluctuations Here, maybe also take a long-term view over the 20th century and even longer, by looking at e.g. Issy Kul Lake Level variations. "],["CaseStudyChirchikRiver.html", "Chapter 3 Case Study - The Chirchik River Basin", " Chapter 3 Case Study - The Chirchik River Basin Charvak reservoir dam, looking downstream. Source: Tobias Siegfried In this Chapter, two Central Asian river basins are presented and extensively discussed. The purpose is to familiarize the reader with key hydrological processes but also to demonstrate ways of hydro-meteorological time series analyses with R (R Core Team 2013). "],["overview.html", "3.1 Overview", " 3.1 Overview The Chirchik is a river in the Tashkent region of Uzbekistan. Its natural basin covers 13’112 km2, not accounting for the modern-time interbasin water transfers to the neighboring Akhangaran basin in the south (the outline of the basin is shown in Figure 3.1) and to the north. In terms of total runoff contribution, it is the biggest right tributary of the Syr Darya (see also further below in Section 3.2.1). The river is formed by the confluence of the Chatkal and the Pskem rivers. They emerge at the south-western end of the Tien Shan mountains, i.e. the Talas Alatau, in the border region of Kyrgyzstan, Kazakhstan and Uzbekistan. The main tributaries are in clock-wise direction starting from north: Ugam, Pskem, Kosku and Chatkal. The Charvak reservoir receives water from these rivers. Ugam is the largest right tributary downstream of the reservoir and Aksak Ata the largest left-side tributary. Below the Charvak hydroelectric power station, the river water gets diverted in numerous canals for irrigation in and around the Tashkent oasis and for interbasin water transfer to the Akhangaran basin in the south. As part of the Chirchik-Bozsuu cascade, several smaller dams along the river serve hydropower production and irrigation purposes. Figure 3.1: Overview over the Chirchik river basin with tributaries and the location of the main gauging stations in the zone of runoff formation and near the confluence with the Syr Darya. Figure 3.1 shows a comprehensive overview of the Chirchik river basin and its tributaries as well as relevant modern gauging stations. Gauges are indicated with the semi-round shapes and the corresponding five digit official code as utilized by the Uzbek Hydrometeorological Service (HMS) indicated. The virtual gauge is not a real gauge in the sense that reservoir inflow is calculated from all contributing tributary flow components, i.e. Chatkal river, Pskem river, Nauvalisoy and Koksu Rivers. Koksu however, with a basin area of 392 km\\(^2\\), is ungauged. Its discharge contribution is calculated using an established empirical relationship between discharge in Chatkal River and discharge in Koksu. The empirical relationship is derived further below in Section 3.3. First, we now turn our attention to the description of key basin characteristics. "],["BasinCharacteristics.html", "3.2 Key Basin Characteristics", " 3.2 Key Basin Characteristics This Section uses a number of available data that are available to characterize the Chirchik River Basin from the hydro-climatological perspective. Data access and modeling is further described in Chapter @ref{HydroModelsEmpiricalModels} in Part II of this Book. 3.2.1 Hydrological Characterization The available discharge data is shown in Figure 3.2. These are near complete historic records. See above Figure 3.1 for the station locations. Figure 3.2: Available discharge data of Chirchik River Basin The discharge measurements at Gazalkent gauge started already in 1900 and is one of the longest records available in Central Asia. The monthly record of the station is shown in Figure 3.3. You can zoom into the time series and investigate it in detail. Figure 3.3: Monthly discharge at Gauge 16262, Gazalkent. As is easily visible, the June 1969 discharge was the historic monthly mean maximum with 1’220 m3/s. The characteristics of the timeseries feature the typical snowmelt-driven runoff pattern with pronounced seasonality and interannual variability. At Chinaz near the confluence of the Chirchik River with the Syr Darya (Gauge 16275), however, a changing discharge regime can be identified over time (Figure 3.4). The drastic decrease in discharge there is due to two effects. First, water diversions and interbasin water transfers for irrigation purposes have greatly increased over the course of the 20th century. Second, the closure of the Charvak dam in 1974 and the subsequent filling of the dam decreased discharge during the filling period. Furthermore, the interannual variability of flows decreased from there onwards due to the now regulated flow regime. This latter effect is also visible at the Gazalkent gauge. The non-stationarity in the discharge timeseries at these stations is thus explained by anthropogenic effects. Figure 3.4: Monthly discharge at Gauge 16275, Chinaz The effect of water diversion becomes even more apparent when the annual discharge at Gazalkent gauging station upstream of any major water diversion and at Chinaz gauge, which is in the very downstream of Chirchik River right before its confluence with the Syr Darya, are compared. The corresponding annual timeseries are shown in Figure 3.5 together with the difference of the two time series. Figure 3.5: Annual discharge at Gauge 16262, Gazalkent and Gauge 16275, Chinaz and the difference of the two timeseries. The difference of the two time series is from the allocation of water for human purposes, mostly for irrigation. Figure 3.5 shows the growing water allocation in the catchment from the 1930ies up to the end of the 20th century. Allocation grew almost 3-fold over this period. Interestingly, in the first decade of the 21st century, trends in allocation completely revered and in 2009, roughly one third of the total flow at Gazalkent was allocated consumptively. The trend reversal might be due to a change in irrigation policy, problems with intake infrastructure or both. ## # A tibble: 7 x 5 ## # Groups: code [7] ## code mean min max sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 16262 229. 48.7 1220 186. ## 2 16275 105. 1.2 912 121 ## 3 16279 116. 21.1 729 110. ## 4 16290 79.4 12.7 438 69.3 ## 5 16298 3.8 0.9 21.1 2.8 ## 6 16300 22.4 3.9 114 19.3 ## 7 16924 205. 40.7 1231 183. Table 3.1: Key statistics of Chirchik basin rivers. code mean min max sd 16262 228.6 48.7 1220.0 186.4 16275 104.9 1.2 912.0 121.0 16279 115.7 21.1 729.0 109.9 16290 79.4 12.7 438.0 69.3 16298 3.8 0.9 21.1 2.8 16300 22.4 3.9 114.0 19.3 16924 205.3 40.7 1231.0 183.2 The largest left tributary to Chirchik below the Charvak reservoir Aksak Ata. The gauging station on the river got dismantled a long time ago. An average long-term mean discharge of 2.35 m\\(^{3}\\)/s is a solid estimated of its contribution to the overall discharge of Chirchik. Thus, if we add up long-term average discharge at Gazalkent and the one from Aksak Ata we obtain an annual norm discharge of 231 m\\(^{3}\\)/s. Chirchik river is thus the biggest right-tributary to the Syr Darya. Chatkal river contributes exactly half to it (115.7 m\\(^{3}\\)/s) and Pskem river approximately one third (34.4% or 79.4 m\\(^{3}\\)/s). Nauvalisoy is only a very small river with 1.6 % runoff contribution (3.8 m\\(^{3}\\)/s). From the available data, the long-term average runoff contribution by the ungauged Koksu river can be estimated to be 6.4 m\\(^{3}\\)/s or 2.8 %. Downstream of the reservoir, Ugam river contributes an additional 9.7 % (22.4 m\\(^{3}\\)/s) to the total flow. Let us now turn our attention to the seasonality of the tributaries. We exclude both, the Chinaz Gauge and Gazalkent Gauge data in our analysis for the above-mentioned reason that flow there is no longer representing a natural runoff regimes there. We thus plot seasonalities of the key gauged and unregulated tributaries , i.e. Chatkal, Pskem, Nauvalisoy and Ugam rivers in Figures 3.6 and 3.7 below. Figure 3.6: Seasonality diagnostics of the two large tributaries, i.e. the Chatkal and Pskem rivers. Discharge seasonality of the gauging stations downstream of Charvak reservoir is shown below. Note that we only have monthly values for Ugam station which explains the appearance of the weekly plot in the upper right panel of Figure 3.7. Figure 3.7: Seasonality diagnostics of the two minor tributaries taht are gauged. The seasonality with the spring and summer runoff peaks is striking in all the rivers. Nauvalisoy discharge peaks, on average, during or around week 20. Chatkal river discharge peaks around week 23 and Pskem river around week 26. These differences can be explained with the difference in mean catchment elevations which are as follows: Nauvalisoy catchment: 2’160 masl, Ugam catchment: 803 masl, Chatkal catchment: 2’692 masl, and Pskem Catchment: 2’795 masl where Ugam is the lowest lying and Pskem catchment the highest catchment (see also Chapter 2 for more information). Figure 3.8 shows the hypsometric curves of the main tributaries to the Chirchik River. Figure 3.8: Hypsometric Curves of the tributaries to the Chirchik River Basin. Using a LOESS smoother, we can remove discharge time series seasonality and catch a glimpse of the underlying longterm trends. This is shown for gauging station 16294, i.e. the inflow to the Charvak Reservoir, in Figure 3.9. If anything, a slightly increasing trend in mean discharge can be observed over the last 40 years. We will further discuss this finding also in the context of the analysis of the meteorological data record in the next Section. Figure 3.9: Changes in mean monthly discharges are plotted with black lines over the entire observational record for Charvak Reservoir gauge (16924).The blue line shows a smoothed trend using a LOESS-smoother. But what about changes for particular seasons and months? To understand these changes, we plot monthly average data grouped together individually for all months. Figure 3.10 shows the resulting graphs together with their best fit regression lines for each month. Several interesting observations can be done. Figure 3.10: Changes in mean monthly discharges are plotted with black lines over the entire observational record for Charvak Reservoir gauge (16924).The red lines are the per month best fit regression lines. First, cold season discharge in quarter 1 (Q1) and Q4 have a slightly increasing trend. Converse to this, the warm season quarterly trends are not uniform where Q2 trends are strongly increasing and Q3 trends are markedly decreasing. This is in line with what one would expect from a warming climate, i.e. that the snow-melt driven hydrograph peak flows shift in their timing towards earlier towards spring. At the same time, Q3 warm season discharge diminishes because of the earlier snowmelt, assuming no changes in the precipitated water. We will investigate the available climate and precipitation record in the following section. Figure 3.11: The plates show mean, minimum and maximum quarterly discharges for Q1 (upper left plate), Q2 (upper right plate), Q3 (lower left plate) and Q4 (lower right plate). All values are in mean quarterly discharge per second The development of the quarterly minimum, maximum and mean discharge Q over the years for Gauge 16924 (Charvak reservoir inflow) is shown in Figure 3.11. The increasing trends in cold season discharge (Q1 and Q4) is confirmed. In these quarters, minimum, mean and maximum discharges appear to increase with a probably link to temperature increases during these quarters (see Section 3.2.2 for a discussion). In Q2, minimum and mean discharges have an increasing trend. In Q3, maximum discharge appears to decrease over time. 3.2.2 Climatological Characterization Long-term climate data from three different stations located in the vicinity and upstream of Charvak Reservoir is available. The stations are meteostation 38642 and 38339, both in Pskem River Basin, Meteostation 38471, Chatkal River Basin and Meteostation 38464 in the vicinity of the Charvak Reservoir (see also Figure 3.1 above for their locations. The raw temperature data is shown in Figure 3.12 whereas the per month temperature trends are shown in Figures 3.13 and 3.14. At both stations, a significant cold season warning trend is visible. Figure 3.12: Available decadal temperature records at Pskem and Chatkal meteorological stations. The record at the Kyrgyz Chatkal Meteo Station shows a large data gap in the post-transition years. The blue trend lines (LOESS smoother) indicate an increasing temperature trend at both mountain stations. Figure 3.13: Changes in mean monthly temperatures are plotted with black lines over the entire observational record for Pskem meteorological station.The red lines are the per month best fit regression lines. Figure 3.14: Changes in mean monthly temperatures are plotted with black lines over the entire observational record for Pskem meteorological station. The red lines are the per month best fit regression lines. The peak in the month of September is an outlier. Similarily to the analysis carried out above for the development of quarterly flows, we can analyze the development of quarterly temperature statistics. Figure (fig:quarterlyMeanMinMaxT_38462) shows the result. (#fig:quarterlyMeanMinMaxT_38462)Development of mean, minimum and maximum quarterly temperatures for Q1 at Station 38462 Figure 3.15: Available decadal and monthly data records from different meteorological stations that are located in the zone of runoff formation. As in the case of temperature, the precipitation record at the Kyrgyz Chatkal Meteo Station shows a large data gap in the post-transition years. Figure 3.16: Development of mean, minimum and maximum quarterly temperatures for Q1 at Station 38462 Investigate temperature precipitation link q1TP &lt;- left_join(q1T ,q1P ,by=c(&#39;date&#39;,&#39;name&#39;)) %&gt;% rename(T=value.x,P=value.y) p1 &lt;- q1TP %&gt;% na.omit() %&gt;% ggplot(aes(x=T,y=P)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;lm&quot;) q2TP &lt;- left_join(q2T ,q2P ,by=c(&#39;date&#39;,&#39;name&#39;)) %&gt;% rename(T=value.x,P=value.y) p2 &lt;- q2TP %&gt;% na.omit() %&gt;% ggplot(aes(x=T,y=P)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;lm&quot;) q3TP &lt;- left_join(q3T ,q3P ,by=c(&#39;date&#39;,&#39;name&#39;)) %&gt;% rename(T=value.x,P=value.y) p3 &lt;- q3TP %&gt;% na.omit() %&gt;% ggplot(aes(x=T,y=P)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;lm&quot;) q4TP &lt;- left_join(q4T ,q4P ,by=c(&#39;date&#39;,&#39;name&#39;)) %&gt;% rename(T=value.x,P=value.y) p4 &lt;- q4TP %&gt;% na.omit() %&gt;% ggplot(aes(x=T,y=P)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;lm&quot;) p &lt;- list(p1,p4) cowplot::plot_grid(plotlist = p,nrow = 1,ncol = 2) Investigate temperature discharge link q1TQ &lt;- left_join(q1T ,q1Q ,by=c(&#39;date&#39;,&#39;name&#39;)) %&gt;% rename(T=value.x,Q=value.y) p1 &lt;- q1TQ %&gt;% na.omit() %&gt;% ggplot(aes(x=T,y=Q)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;lm&quot;) q2TQ &lt;- left_join(q2T ,q2Q ,by=c(&#39;date&#39;,&#39;name&#39;)) %&gt;% rename(T=value.x,Q=value.y) p2 &lt;- q2TQ %&gt;% na.omit() %&gt;% ggplot(aes(x=T,y=Q)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;lm&quot;) q3TQ &lt;- left_join(q3T ,q3Q ,by=c(&#39;date&#39;,&#39;name&#39;)) %&gt;% rename(T=value.x,Q=value.y) p3 &lt;- q3TQ %&gt;% na.omit() %&gt;% ggplot(aes(x=T,y=Q)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;lm&quot;) q4TQ &lt;- left_join(q4T ,q4Q ,by=c(&#39;date&#39;,&#39;name&#39;)) %&gt;% rename(T=value.x,Q=value.y) p4 &lt;- q4TQ %&gt;% na.omit() %&gt;% ggplot(aes(x=T,y=Q)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;lm&quot;) p &lt;- list(p1,p4) cowplot::plot_grid(plotlist = p,nrow = 1,ncol = 2) Precipitation - Discharge Link q1PQ &lt;- left_join(q1P,q1Q ,by=c(&#39;date&#39;,&#39;name&#39;)) %&gt;% rename(P=value.x,Q=value.y) p1 &lt;- q1PQ %&gt;% na.omit() %&gt;% ggplot(aes(x=P,y=Q)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;lm&quot;) q2PQ &lt;- left_join(q2P,q2Q ,by=c(&#39;date&#39;,&#39;name&#39;)) %&gt;% rename(P=value.x,Q=value.y) p2 &lt;- q2PQ %&gt;% na.omit() %&gt;% ggplot(aes(x=P,y=Q)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;lm&quot;) q3PQ &lt;- left_join(q3P,q3Q ,by=c(&#39;date&#39;,&#39;name&#39;)) %&gt;% rename(P=value.x,Q=value.y) p3 &lt;- q3PQ %&gt;% na.omit() %&gt;% ggplot(aes(x=P,y=Q)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;lm&quot;) q4PQ &lt;- left_join(q4P,q4Q ,by=c(&#39;date&#39;,&#39;name&#39;)) %&gt;% rename(P=value.x,Q=value.y) p4 &lt;- q4PQ %&gt;% na.omit() %&gt;% ggplot(aes(x=P,y=Q)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;lm&quot;) p &lt;- list(p1,p2,p3,p4) cowplot::plot_grid(plotlist = p,nrow = 1,ncol = 4) Q1 versus Q2 q1QQ &lt;- q1Q %&gt;% add_column(Q2=q2Q$value) %&gt;% rename(Q1=value) p1 &lt;- q1QQ %&gt;% na.omit() %&gt;% ggplot(aes(x=Q1,y=Q2)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;loess&quot;) q2QQ &lt;- q2Q %&gt;% add_column(Q3=q3Q$value) %&gt;% rename(Q2=value) p2 &lt;- q2QQ %&gt;% na.omit() %&gt;% ggplot(aes(x=Q2,y=Q3)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;loess&quot;) # q3QQ &lt;- q3Q %&gt;% add_column(Q4=q4Q$value) %&gt;% rename(Q3=value) # p3 &lt;- q3QQ %&gt;% na.omit() %&gt;% ggplot(aes(x=Q3,y=Q4)) + geom_point() + geom_smooth(formula = y ~ x,method = &quot;loess&quot;) p &lt;- list(p1,p2) cowplot::plot_grid(plotlist = p,nrow = 1,ncol = 2) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% "],["CRBKoskuDischargeContribution.html", "3.3 The Estimation of Discharge Contributions by the Ungauged Kosku Tributary", " 3.3 The Estimation of Discharge Contributions by the Ungauged Kosku Tributary Before the closure of the Charvak dam and the subsequent filling of the reservoir in and after 1974, the HydroMet experts started a detailed 3-years measurement comparison campaign at Charvak gauge and at gauge 16279 in Khudaydod (see Figure 3.1). Both are located on Chatkal river. Charvak gauge had to be decommissioned after the closure of the dam because it got flooded. The confluence of Koksu river with Charvak river is just upstream of the former Charvak gauge. Using daily data from the measurement comparisons campaign, the HydroMet experts could then relate Charvak gauge discharge to Khudaydod discharge using a linear relationship. At the same time, they were now able to relate Koksu discharge to the discharge at Chatkal River in Khudaydod in the following manner \\[ Q_{Koksu} \\propto Q_{Charvak} - Q_{16279} \\] We show the procedure here. After loading the riversCentralAsia Package as shown above, the relevant daily data from 01/01/1965 - 31/12/1967 can be loaded. KoksuDischargeDerivation &lt;- riversCentralAsia:::KoksuDischargeDerivation # load Data Please not that, unless otherwise mentioned, all data from discharge meteorological stations utilized in this book are from the Uzbek HMS. The data is stored in long format, meaning that measurements in time and for the two gauging stations are just stacked on top of each other in one long table. For the purpose here, we prefer the wide format where we have one date column with unique dates and then the data listed for each station in corresponding columns. KoksuDischarge_wide &lt;- KoksuDischargeDerivation %&gt;% pivot_wider(id_cols = &#39;date&#39;,values_from = &#39;data&#39;,names_from = &quot;code&quot;) KoksuDischarge_wide ## # A tibble: 988 x 3 ## date Charvak `16279` ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1965-01-01 35.6 33.4 ## 2 1965-01-02 35.6 32.4 ## 3 1965-01-03 33 30.4 ## 4 1965-01-04 33 29.4 ## 5 1965-01-05 33 30.4 ## 6 1965-01-06 33 30.4 ## 7 1965-01-07 34.3 31.4 ## 8 1965-01-08 35.6 32.4 ## 9 1965-01-09 38.4 34.4 ## 10 1965-01-10 35.6 32.4 ## # … with 978 more rows The runoff contribution of Koksu can be calculated in a simple manner. # Adding Koksu discharge to the dataframe KoksuDischarge_wide &lt;- KoksuDischarge_wide %&gt;% mutate(Koksu = Charvak - `16279`) KoksuDischarge_wide ## # A tibble: 988 x 4 ## date Charvak `16279` Koksu ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1965-01-01 35.6 33.4 2.2 ## 2 1965-01-02 35.6 32.4 3.2 ## 3 1965-01-03 33 30.4 2.6 ## 4 1965-01-04 33 29.4 3.6 ## 5 1965-01-05 33 30.4 2.6 ## 6 1965-01-06 33 30.4 2.6 ## 7 1965-01-07 34.3 31.4 2.90 ## 8 1965-01-08 35.6 32.4 3.2 ## 9 1965-01-09 38.4 34.4 4 ## 10 1965-01-10 35.6 32.4 3.2 ## # … with 978 more rows The relationship can now be visualized. # and visualize ggplot(KoksuDischarge_wide, aes(`16279`, Koksu)) + geom_point() + xlab(bquote(&#39;Discharge at Gauge 16279 Khudaydod in&#39;~m^3/s)) + ylab (bquote(&#39;Koksu river discharge in&#39;~m^3/s)) We can perform a linear regression to related discharge at Khudaydod to the one at Koksu. The coefficients of the linear regression can be obtained in the following way: lm &lt;- lm(Koksu ~ 0 + `16279`,KoksuDischarge_wide) summary(lm) ## ## Call: ## lm(formula = Koksu ~ 0 + `16279`, data = KoksuDischarge_wide) ## ## Residuals: ## Min 1Q Median 3Q Max ## -38.295 -5.867 -1.918 1.416 120.419 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## `16279` 0.14469 0.00298 48.55 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 12.4 on 987 degrees of freedom ## Multiple R-squared: 0.7049, Adjusted R-squared: 0.7046 ## F-statistic: 2357 on 1 and 987 DF, p-value: &lt; 2.2e-16 Please note, in the specification of the linear model we add the 0 term to force the regression through the origin. Hence, the discharge of Koksu River can be estimated to be \\[ Q_{Koksu} = 0.145 * Q_{Khudaydod} \\] "],["ManualWaterBalance.html", "Chapter 4 The Manual Water Balance", " Chapter 4 The Manual Water Balance Although the general water balance equation is straight forward, setting up a water balance over a specific region and time period is more involved and generally requires an iterative approach. This Chapter will give you a very brief overview over the theory behind the water balance and guide you through an example to set up a regional water balance for an irrigated area in the Fergana valley. "],["site-problem-description.html", "4.1 Site &amp; problem description", " 4.1 Site &amp; problem description "],["identification-of-the-dominant-flow-processes.html", "4.2 Identification of the dominant flow processes", " 4.2 Identification of the dominant flow processes At the start of a water balance is a preliminary estimate of the individual components of the water flow processes. These will be iteratively refined as the water balance boundaries are verified. The first estimate can be made from the office, prior to the field visit, based on open-source data and literature values. 4.2.1 Precipitation Do the ERA5 thingy ### Evaporation ### Transpiration 4.2.2 Canopy interception Neglect, literature 4.2.3 Snowmelt Neglect based on ERA5 temperature data 4.2.4 Runoff Rough estimate based on previous chapter? 4.2.5 Infiltration Rough estimates of irrigation water demand, irrigation norms, literature 4.2.6 Sub-surface flow No data, estimate with water balance 4.2.7 Sublimation Neglect, no snow 4.2.8 Percolation Neglect, shallow groundwater table "],["the-general-water-balance-equation.html", "4.3 The general water balance equation", " 4.3 The general water balance equation In Chapter 2.2, a long-term average water balance over Central Asian mountain area has been presented. In more general terms, the water balance equals the sum of all water sources in a system to the sum of all water sinks in a system plus the change of the water storage in the system over a defined time period (Eq. (4.1)). \\[\\begin{equation} \\tag{4.1} \\sum_i \\text{Sources} = \\sum_j \\text{Sinks} + \\frac{\\Delta \\text{Storage}}{\\Delta t} \\quad, \\in \\Omega \\end{equation}\\] It is important to realize that a balance is always drawn over the well-defined boundaries of a system (\\(\\Omega\\)) and over a specified time period (\\(\\Delta t\\)). "],["boundaries-of-the-water-balance.html", "4.4 Boundaries of the water balance", " 4.4 Boundaries of the water balance Whether a flow process constitutes a source of water for a system or a sink depends on the boundaries of the system. If we calculate the water balance of the air above Central Asia, precipitation constitutes a water loss. If, on the other hand, the boundaries of the water balance are around the soil surface, precipitation is a source of water. In space and time, selection of appropriate level of abstraction "],["data-need-for-a-water-balance.html", "4.5 Data need for a water balance", " 4.5 Data need for a water balance "],["setting-up-a-conceptual-model.html", "4.6 Setting up a conceptual model", " 4.6 Setting up a conceptual model "],["HydroModelsEmpiricalModels.html", "Chapter 5 Discharge Forecasting with Predictive Inference ", " Chapter 5 Discharge Forecasting with Predictive Inference "],["prerequisites.html", "Prerequisites", " Prerequisites This is the first ‘practical’ Chapter of the book and comes with software requirements. For the analysis of the available data we use R (R Core Team 2013). R is a computer language and environment for data analysis, statistical computation and data visualization. It can be downloaded at &lt;https://www.r-project.org&gt;. Together with R, we are using RStudio as the IDE (Team’ 2020). Some core R software packages used in this Chapter need to be installed so that the analyses can be done as shown there. The installation can be done in the following way: # Core Libraries install.packages(&#39;tidyverse&#39;) # Meta - dplyr, ggplot2, purrr, tidyr, stringr, forcats install.packages(&#39;lubridate&#39;) # date and time install.packages(&#39;timetk&#39;) # Time series data wrangling, visualization and preprocessing # Extras if (!require(devtools)) install.packages(&quot;devtools&quot;, repos = &quot;http://cran.us.r-project.org&quot;) # install_github(&quot;boxuancui/DataExplorer&quot;, ref=&quot;develop&quot;) # Simplifies and automates EDA process and reporting # Data and helper functions devtools::install_github(&quot;hydrosolutions/riversCentralAsia&quot;) The packages can then be loaded and made available in your R session. library(devtools) library(tidyverse) library(lubridate) library(timetk) library(DataExplorer) library(riversCentralAsia) When other, additional packages are needed, they will be loaded in the corresponding Sections below. Please also remember the following rules when working with R dataframes in the tidyverse: Every column is variable. Every row is an observation. Every cell is a single value. A final note. In all of the following, we mostly use the powerful data manipulation and visualization techniques for time series data as provided by the timetk package. This package is in active development and greatly facilitates any work with time series data as it, among other things, nicely integrates with the R ‘tidyverse.’ "],["Chap9PredictiveInference.html", "5.1 Forecasting Using Predictive Inference", " 5.1 Forecasting Using Predictive Inference In this Section, we are concerned with predictive inference using observed data to predict future data that is not known yet but that is important to forecast with high confidence and low uncertainty. In other words, it is assumed that we can encapsulate historic patterns in a model a learn about the future with such model. In hydrology, we are dealing with time series, i.e. ordered observations in time. A generic model structure thus can be specified in the following way \\[ y(t+\\Delta t) = f(y(t),x(t)) + \\epsilon(t) \\] where \\(y(t+\\Delta t)\\) is called the forecast target (discharge at a particular gauge in our case) and is the variable that we want to forecast in the future, i.e. \\(\\Delta t\\) time away from now. \\(y(t)\\) denotes past known observations of discharge up and including time \\(t\\). Similarly, \\(x(t)\\) denotes other variables of interest, called external regressors, that might be relevant to obtain good quality forecasts such as meteorological data from local stations, including precipitation and temperature. Finally, \\(f()\\) denotes the type of model that is being used for forecasting and \\(\\epsilon\\) are the time-dependent error terms. If, for example, one would use a linear modeling approach without external regressors, such type of model could simply be written as \\[ y(t+\\Delta t) = \\beta_{0} + \\beta_{1} \\cdot y(t) + \\epsilon(t) \\] In the model specification above, the aim is to predict into the future with a lead time of \\(\\Delta t\\), i.e. for example one month ahead. The lead-time model can be written in equivalent form using lags in the following way \\[ y(t) = f(y(t-lag),x(t-lag)) + \\epsilon(t) \\] where \\(lag = \\Delta t\\). This just means that we use all the available observations until and including \\(t-lag\\) for predicting the target at time \\(t\\). We will use this specification throughout the Chapter when working with and developing new forecasting models feature engineering experimentation and ensembling Knowledge of key events, i.e. date shifts holidays Deep learning (data permitting) Boosting errors "],["forecasting-in-the-central-asian-hydromets.html", "5.2 Forecasting in the Central Asian Hydromets", " 5.2 Forecasting in the Central Asian Hydromets 5.2.1 Background The key agencies that that are charged in predicting river discharge regularly in Central Asia are the Hydrometeorological Agencies. For predicting mean discharge over a certain future period, they use different types of statistical models. The particular type of model they use depends on the available hydrological and meteorological data for a particular river whose mean discharge is to be forecasted and on the type of the forecast. Types of forecasts include daily forecasts, i.e. \\(\\Delta t = 1 \\text{ day}\\), pentadal forecasts, i.e. \\(\\Delta t = 5 \\text{ days}\\), decadal forecasts, i.e. \\(\\Delta t = 10 \\text{ days}\\), monthly forecasts, i.e. \\(\\Delta t = 1 \\text{ month}\\), and seasonal forecasts, i.e. \\(\\Delta t = 6 \\text{ months}\\). To this date, these types of forecasts are performed at regular intervals by the operational hydrologists. Normally, this requires normally a lot of manual work. Recently, selected Hydrometeorological Agencies use automated software to automatize this type of work3. In Uzbekistan, for example, the following list of forecast objects exists in the Hydromet. List of Uzbek forecast target objects. Forecast type abbreviations are dl: daily forecast, m: monthly forecast, s: seasonal forecast. Country abbreviations are UZ: Uzbekistan, KG: Kyrgyzstan and TJ: Tajikistan. Source: Uzbek Hydrometeorological Service. River Gauge (Target Object) Gauge Code Country Types of Forecasts Chirchik Inflow to Charvak Res. 16924 UZ dl, m, s Chirchik Inflow to Charvak Res. + Ugam River 16924 + 16300 UZ m, s Akhangaran Irtash 16230 UZ m, s Chadak Dzhulaysay 16202 UZ m, s Gavasay Gava 16193 UZ m, s Padsha-Ata Tostu 16176 KG m, s Kara Darya Inflow to Andizhan water reservoir 16938 UZ/KG dl, m, s Isfayramsoy Uch-Kurgan 16169 KG m, s Sokh Sarykanda 16198 UZ dl (May - Sep.), m, s Sanzar Kyrk 16223 UZ m, s Naryn Inflow to Toktogul water reservoir 16936 KG m, s Vaksh Inflow to Nurek water reservoir 17084 (Vakh river - Darband gauge) TJ m, s Kafirnigan Tartki 17137 TJ m, s Tupalang Inflow to Tupalang water reservoir 17194 UZ m, s Sangardak Keng-Guzar 17211 UZ m, s Akdarya Inflow to Gissarak water reservoir 17464 (Akfariya river - Hissarak gauge) UZ m, s Yakkabagdarya Tatar 17260 UZ m, s Uryadariya + Kichik Uryadariya Inflow to Pachkamar water reservoir 17279 (Uryadariya river - Bazartepe gauge) + 17275 (Kichik Uryadariya - Gumbulak gauge) UZ m, s Zeravshan Inflow to Rovatkhodzha hydro work 17461 UZ m, s It should be noted that all of the Hydromets have such type of lists with different forecast target and types. As can be seen from the above list, Uzbekistan does neither issue pentade nor decadal forecasts, i.e. types of forecasts which are widely used in the Kyrgyz Hydromet in contrast. Finally, seasonal forecasts in the Uzbek Hydromet are issued twice prior to the irrigation season with 3. - 5. March being the first issues data range and 3. - 5. April being the second one. Converse to this, monthly forecasts are issues between the 25. - 27. day each month. Finally, decadal and pentade forecasts are issued each morning at the day of the end of the corresponding pentade or decade. It is important to emphasize again that there is currently no standardized way in the region to produce these forecasts. While in some instances, a particular approach and method works very well, it fails to produce acceptable forecasts in other basins. However, as we shall see, certain techniques work very well for particular forecast horizons which then explains why such type of technique has become widely used in the region. 5.2.2 Forecasting for What and Whom? Why is all this work is required? What is the purpose of predicting mean discharge into the future at regular intervals? Important recipients of the forecast products include the Water Authorities which are in charge of delivering adequate amounts of water for irrigation at the right time and location. It all starts with pre-season irrigation planning. The main irrigation season in most of Central Asia is from April 1. through the end of September. Previous to the start of the irrigation season, irrigation plans are drafted based on computed irrigation water demand of all the water users that are connected to a particular irrigation system. These irrigation system are defined in terms of canal topology where demand gets aggregated from the bottom up to the Rayvodkhozes and the Oblvodkhozes. The later then starts with the pre-season irrigation planning given the water irrigation system-level demand. These plans specify decadal water discharge for each irrigation system and the corresponding canals. Demand is one thing, but expected supply from the Central Asian rivers another. In order to be able to match the irrigation water demand, the water authorities do what is needed and receive from the Hydromets first the seasonal discharge forecasts. Given this forecast of irrigation-season water availability, the water authorities then adjust their plans given the particular expected circumstances. If, for example, an exceptionally dry year is expected, they activate limit plans and reduce planned water distributions according to forecasted quantities. If a wet year is expected, they do not perform these adjustments and maybe even release water from reservoirs previous to the irrigation season to ensure enough storage capacity in the reservoirs. With the beginning of the irrigation season, another seasonal forecast is carried out by the Hydromets and communicated to the Central Asian water authorities. Given the updated forecast, planning is revised and adjusted accordingly. Then, finally, throughout the irrigation season pentadal, decadal and monthly forecasts are produced constantly to carefully balance water demand with supplies while the season is under way. Needless to say that other important customers for hydrometeorological forecasts exist, including for example airports, road departments that need to ensure road safety, agricultural clusters that are interested in frost and hail warnings, local authorities that need to be alerted in the case of extreme local weather conditions, etc. The software used is called iEasyHydro and currently operationalized in the Kyrgyz Hydromet. Other Hydromets are testing the software (as of 2020). More information about iEasyHydro can be obtained by contacting the author.↩︎ "],["Chap9DataPreparation.html", "5.3 Data and Preparation", " 5.3 Data and Preparation 5.3.1 Available Data The riversCentralAsia Package provides available data of the gauging and meteorological stations in the Chirchik River Basin. Before starting any type of modeling, it is important to get a good understanding of the data that we are dealing with and whether there exist problems with the raw data that need to be addressed prior to modeling. Problems usually include data gaps and outliers as data record that one obtains are usually ever complete nor clean of errors. The steps performed here are thus required steps for any type of successful modeling and should be performed with great care. We concentrate our efforts here on discharge records and data from meteorological stations in the Chirchik River Basin. The techniques shown here for decadal (10-days) data naturally extend to monthly data and other basins. 5.3.2 Gap Filling Discharge Data In the following, we will work with decadal discharge data from the two main tributaries, i.e. the Chatkal and (Gauge 16279) Pskem rivers (Gauge 16290) and the data of the inflow to the Charvak reservoir (Gauge 16924). The goal is to analyze the data and prepare for modeling. First, let us load the relevant discharge data. data &lt;- ChirchikRiverBasin # load data q_dec_tbl &lt;- data %&gt;% filter(code == &#39;16279&#39; | code == &#39;16290&#39; | code == &#39;16924&#39;) # Note for the new name of the object, we choose to add periodicity (_dec_) and data type (_tbl for tibble/dataframe) to the data name. This just helps to stay organized and is good practice in R programming. q_dec_tbl ## # A tibble: 9,072 x 14 ## date data norm units type code station river basin resolution ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; ## 1 1932-01-10 48.8 38.8 m3s Q 16279 Khuday… Chat… Chir… dec ## 2 1932-01-20 48.4 37.5 m3s Q 16279 Khuday… Chat… Chir… dec ## 3 1932-01-31 42.4 36.6 m3s Q 16279 Khuday… Chat… Chir… dec ## 4 1932-02-10 43.7 36.4 m3s Q 16279 Khuday… Chat… Chir… dec ## 5 1932-02-20 44.2 36.3 m3s Q 16279 Khuday… Chat… Chir… dec ## 6 1932-02-29 47.7 36.9 m3s Q 16279 Khuday… Chat… Chir… dec ## 7 1932-03-10 54.1 39.4 m3s Q 16279 Khuday… Chat… Chir… dec ## 8 1932-03-20 63.2 47.6 m3s Q 16279 Khuday… Chat… Chir… dec ## 9 1932-03-31 103 60.5 m3s Q 16279 Khuday… Chat… Chir… dec ## 10 1932-04-10 103 86.4 m3s Q 16279 Khuday… Chat… Chir… dec ## # … with 9,062 more rows, and 4 more variables: lon_UTM42 &lt;dbl&gt;, ## # lat_UTM42 &lt;dbl&gt;, altitude_masl &lt;dbl&gt;, basinSize_sqkm &lt;dbl&gt; You can get more information about the available data by typing ?ChirchikRiverBasin. It is advisable to check at this stage for missing data in time series and to fill gaps where present. As can be seen in Figure 5.1 , close inspection of the time series indeed reveals some missing data in the 1940ies. q_dec_tbl %&gt;% plot_time_series(date,data, .facet_vars = code, .smooth = FALSE, .interactive = TRUE, .x_lab = &quot;year&quot;, .y_lab = &quot;m^3/s&quot;, .title = &quot;&quot; ) Figure 5.1: Discharge data of selected gauges in the upstream zone of runoff formation in the Chirchik River Basin. Data Source: Uzbek Hydrometeorological Service. Figure 5.1 and the following Figures are interactive, so you can zoom in to regions of interest. Missing data are also confirmed by the warning that the function timetk::plot_time_series() throws (suppressed here). Statistics of the missing data can be easily obtained. As the Table below shows, we can do this analysis for each discharge station separately. q_dec_tbl %&gt;% group_by(code) %&gt;% summarize(n.na = sum(is.na(data)), na.perc = n.na/n()*100) ## # A tibble: 3 x 3 ## code n.na na.perc ## * &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 16279 15 0.496 ## 2 16290 39 1.29 ## 3 16924 42 1.39 Summarizing the number of observation with missing data reveals 15 data points for station 16279 (0.5 % of total record length) and 39 for station 16290 (1.3 % of total record length). As there are only very few gaps in the existing time series, we use a simple method to fill these. Wherever there is a gap, we fill in the corresponding decadal norm as stored in the norm column in the object q_dec_tbl. The visualization of the results confirms that our simple gap filling approach is indeed satisfactory (Figure 5.2). q_dec_filled_tbl &lt;- q_dec_tbl q_dec_filled_tbl$data[is.na(q_dec_filled_tbl$data)] = q_dec_filled_tbl$norm[is.na(q_dec_filled_tbl$data)] # Gap filling step q_dec_filled_tbl %&gt;% plot_time_series(date, data, .facet_vars = code, .smooth = FALSE, .interactive = TRUE, .x_lab = &quot;year&quot;, .y_lab = &quot;m^3/s&quot;, .title = &quot;&quot; ) Figure 5.2: Gap filled Pskem and Chatkal river discharges. A note of caution here. This simple gap filling technique reduces variance in the time series. It should only be used when the percentage of missing data is low. As will be discussed in the next Section 5.3.3 below, better techniques have to be utilized when there exist substantial gaps and in the case of less regular data. Finally, we discard the norm data which we used for gap filling of the missing discharge data and convert the data to wide format (see the Table below) to add to it meteorological data in the next Section. q_dec_filled_wide_tbl &lt;- q_dec_filled_tbl %&gt;% # again we use the name convention of objects as introduced above mutate(code = paste0(&#39;Q&#39;,code %&gt;% as.character())) %&gt;% # Since we convert everything to long form, we want to keep information as compact as possible. Hence, we paste the type identifier (Q for discharge here) in from of the 5 digit station code. select(date,data,code) %&gt;% # ... and then ditch all the remainder information pivot_wider(names_from = &quot;code&quot;,values_from = &quot;data&quot;) # in order to pivot to the long format, we need to make a small detour via the wide format. q_dec_filled_long_tbl &lt;- q_dec_filled_wide_tbl %&gt;% pivot_longer(-date) # and then pivot back q_dec_filled_wide_tbl ## # A tibble: 3,024 x 4 ## date Q16279 Q16290 Q16924 ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1932-01-10 48.8 38.3 87.1 ## 2 1932-01-20 48.4 37.7 86.1 ## 3 1932-01-31 42.4 36.2 78.6 ## 4 1932-02-10 43.7 35.6 79.3 ## 5 1932-02-20 44.2 35 79.2 ## 6 1932-02-29 47.7 37.1 84.8 ## 7 1932-03-10 54.1 43.1 97.2 ## 8 1932-03-20 63.2 47 110 ## 9 1932-03-31 103 72.1 175 ## 10 1932-04-10 103 73.2 176 ## # … with 3,014 more rows As a result, we now have a complete record of decadal discharge data for the two main tributaries of the Chirchik river and the inflow time series to Charvak Reservoir from the beginning of 1932 until and including 2015, i.e. 84 years. The same type of preparatory analysis will now be carried out for the meteorological data. 5.3.3 Gap Filling Meteorological Data Here, we use precipitation and temperature data from Pskem (38462), Chatkal (38471) and Charvak Reservoir (38464) Meteorological Stations (see Chapter 3 for more information on these stations). We also have data from Oygaing station (Station Code 38339) but the record only starts in 1962 and the time resolution is monthly. Therefore, we do not take this station into account here for the time being. We start with precipitation and plot the available data. p_dec_tbl &lt;- data %&gt;% filter(type==&quot;P&quot; &amp; code!=&quot;38339&quot;) p_dec_tbl %&gt;% plot_time_series(date,data, .facet_vars = code, .interactive = TRUE, .smooth = FALSE, .title = &quot;&quot;, .y_lab = &quot;mm/decade&quot;, .x_lab = &quot;year&quot; ) Figure 5.3: Raw decadal precipitation data from Pskem (38462), Charvak Reservoir (38471) and Chatkal Meteo Station (38471). The precipitation data from these 3 stations shows some significant data gaps. The Chatkal Meteorological Station that is located in Kyrgyzstan apparently did not work in the post-transition years and continuous measurements were only resumed there in 1998. Let us see what happens if we were to use the same simple gap filling technique that we introduced above for discharge. p_dec_filled_tbl &lt;- p_dec_tbl p_dec_filled_tbl$data[is.na(p_dec_filled_tbl$data)] = p_dec_filled_tbl$norm[is.na(p_dec_filled_tbl$data)] p_dec_filled_tbl %&gt;% plot_time_series(date,data, .facet_vars = code, .interactive = TRUE, .smooth = FALSE, .title = &quot;&quot;, .y_lab = &quot;mm/decade&quot;, .x_lab = &quot;year&quot; ) Figure 5.4: Precipitation Data gap-filled with norms. The filled values from 1990 - 2000 in the case of the Station 38471 indicate that the norm-filling technique is not good. Closely inspect the significant data gap in the 1990ies at Station 38741 (tip: play around and zoom into the time series in the 1990ies in Figure 5.3 and comparing it with the resulting gap-filled timeseries in Figure ??. We see that our technique of gap filling with long-term norms is not suitable for this type of data and the significant gap size. The effect of variance reduction is also clearly visible. Hence, we resort to a more powerful gap filling technique that uses a (regression) model to impute the missing values from existing ones at the neighboring stations, i.e. Stations 38462 and 38464. To do so, we utilize an R package that is tightly integrated in the tidyverse4. library(simputation) # First, we bring the data into the suitable format. p_dec_wide_tbl &lt;- p_dec_tbl %&gt;% mutate(code = paste0(&#39;P&#39;,code %&gt;% as.character())) %&gt;% select(date,data,code) %&gt;% pivot_wider(names_from = &quot;code&quot;,values_from = &quot;data&quot;) # Second, we impute missing values. p_dec_filled_wide_tbl &lt;- p_dec_wide_tbl %&gt;% impute_rlm(P38471 ~ P38462 + P38464) %&gt;% # Imputing precipitation at station 38471 using a robust linear regression model impute_rlm(P38462 ~ P38471 + P38464) %&gt;% # Imputing precipitation at station 38462 using a robust linear regression model impute_rlm(P38464 ~ P38462 + P38471) # Imputing precipitation at station 38464 using a robust linear regression model p_dec_filled_long_tbl &lt;- p_dec_filled_wide_tbl %&gt;% pivot_longer(c(&#39;P38462&#39;,&#39;P38464&#39;,&#39;P38471&#39;)) p_dec_filled_long_tbl%&gt;% plot_time_series(date,value, .facet_vars = name, .interactive = TRUE, .smooth = FALSE, .title = &#39;&#39;, .y_lab = &quot;mm/decade&quot;, .x_lab = &quot;year&quot; ) (#fig:rawData_P_rlm)Precipitation Data gap filled with a robust linear regression modeling approach As you can see, we use simple linear regression models to impute missing value in the target time series using observations from the neighboring stations. Through simple visual inspection, it becomes clear that this type of regression model for gap filling is better suited than the previous approach chosen. Let us check whether we could successfully fill all gaps with this robust linear regression approach. p_dec_filled_long_tbl %&gt;% group_by(name) %&gt;% summarize(n.na = sum(is.na(value)), n.na.perc = n.na/n()*100) ## # A tibble: 3 x 3 ## name n.na n.na.perc ## * &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 P38462 12 0.402 ## 2 P38464 12 0.402 ## 3 P38471 3 0.100 It turns out that we still have very few gaps to deal with. We can see them by simply visualizing the wide tibble. The problem persisted at times when two or more values were missing across the available stations at the same time and where thus the linear regression could not be carried out. p_dec_filled_wide_tbl %&gt;% head(10) ## # A tibble: 10 x 4 ## date P38462 P38464 P38471 ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1933-01-10 NA NA 2 ## 2 1933-01-20 NA NA 10 ## 3 1933-01-31 NA NA 5 ## 4 1933-02-10 NA NA 33 ## 5 1933-02-20 NA NA 8 ## 6 1933-02-28 NA NA 10 ## 7 1933-03-10 NA NA 31 ## 8 1933-03-20 NA NA 50 ## 9 1933-03-31 NA NA 6 ## 10 1933-04-10 23 21.3 13 p_dec_filled_wide_tbl %&gt;% tail() ## # A tibble: 6 x 4 ## date P38462 P38464 P38471 ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2015-11-10 72 81 19 ## 2 2015-11-20 122 76 43 ## 3 2015-11-30 7 2 3 ## 4 2015-12-10 NA NA NA ## 5 2015-12-20 NA NA NA ## 6 2015-12-31 NA NA NA We can solve the issues related to the missing values at the start of the observation record by using the same technique as above and by only regressing P38462 and P38464 on P38471. p_dec_filled_wide_tbl &lt;- p_dec_filled_wide_tbl %&gt;% impute_rlm(P38462 ~ P38471) %&gt;% # Imputing precipitation at station 38462 using a robust linear regression model impute_rlm(P38464 ~ P38471) # Imputing precipitation at station 38464 using a robust linear regression model p_dec_filled_wide_tbl %&gt;% head(10) ## # A tibble: 10 x 4 ## date P38462 P38464 P38471 ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1933-01-10 5.60 5.08 2 ## 2 1933-01-20 18.3 16.7 10 ## 3 1933-01-31 10.4 9.46 5 ## 4 1933-02-10 54.9 50.3 33 ## 5 1933-02-20 15.2 13.8 8 ## 6 1933-02-28 18.3 16.7 10 ## 7 1933-03-10 51.8 47.3 31 ## 8 1933-03-20 82.0 75.0 50 ## 9 1933-03-31 12.0 10.9 6 ## 10 1933-04-10 23 21.3 13 Converse to this, the complete set of observations is missing for December 2015. We will thus remove these non-observations from our tibble. p_dec_filled_wide_tbl &lt;- p_dec_filled_wide_tbl %&gt;% na.omit() p_dec_filled_wide_tbl %&gt;% tail() ## # A tibble: 6 x 4 ## date P38462 P38464 P38471 ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2015-10-10 5 1 0 ## 2 2015-10-20 89 108 58 ## 3 2015-10-31 34 40 12 ## 4 2015-11-10 72 81 19 ## 5 2015-11-20 122 76 43 ## 6 2015-11-30 7 2 3 p_dec_filled_long_tbl &lt;- p_dec_filled_wide_tbl %&gt;% pivot_longer(-date) Inspecting the temperature data, we see similar data issues as in the precipitation data set. t_dec_tbl &lt;- data %&gt;% filter(type==&quot;T&quot;) t_dec_tbl %&gt;% plot_time_series(date,data, .facet_vars = code, .interactive = TRUE, .smooth = FALSE, .title = &#39;&#39;, .y_lab = &quot;deg. Celsius&quot;, .x_lab = &quot;year&quot; ) (#fig:rawData_T)Raw temperature data from the meteorological stations Pskem (38462) and Chatkal (38471) # First, we bring the data into the suitable format. t_dec_wide_tbl &lt;- t_dec_tbl %&gt;% mutate(code = paste0(&#39;T&#39;,code %&gt;% as.character())) %&gt;% select(date,data,code) %&gt;% pivot_wider(names_from = &quot;code&quot;,values_from = &quot;data&quot;) # Second, we impute missing values. t_dec_filled_wide_tbl &lt;- t_dec_wide_tbl %&gt;% impute_rlm(T38471 ~ T38462) %&gt;% # Imputing precipitation at station 38471 using a robust linear regression model impute_rlm(T38462 ~ T38471) # Imputing precipitation at station 38462 using a robust linear regression model t_dec_filled_long_tbl &lt;- t_dec_filled_wide_tbl %&gt;% pivot_longer(c(&#39;T38462&#39;,&#39;T38471&#39;)) t_dec_filled_long_tbl%&gt;% plot_time_series(date,value, .facet_vars = name, .interactive = TRUE, .smooth = FALSE, .title = &#39;&#39;, .y_lab = &quot;deg. Celsius&quot;, .x_lab = &quot;year&quot; ) (#fig:rawData_T_rlm)Temperature data gap filled with robust linear regression modeling. There are some irregularities in the temperature time series of Chatkal Meteorological Station in the first decade of the 20th century (tip: zoom in to see these more clearly). Note that these were not introduced by the gap filling technique that we used but are most likely wrong temperature readings. We will return to these in the outlier analysis below in Section 5.3.4. t_dec_filled_long_tbl %&gt;% group_by(name) %&gt;% summarize(n.na = sum(is.na(value)), n.na.perc = n.na/n()*100) ## # A tibble: 2 x 3 ## name n.na n.na.perc ## * &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 T38462 3 0.100 ## 2 T38471 3 0.100 To see where the missing value are, we find them easily again by looking at the head and tail of the tibble. t_dec_filled_wide_tbl %&gt;% head() ## # A tibble: 6 x 3 ## date T38462 T38471 ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1933-01-10 -6.9 -16.6 ## 2 1933-01-20 -6.1 -15.5 ## 3 1933-01-31 -6.3 -15.6 ## 4 1933-02-10 -2 -8.6 ## 5 1933-02-20 -3.3 -12.5 ## 6 1933-02-28 -0.1 -8.5 t_dec_filled_wide_tbl %&gt;% tail() ## # A tibble: 6 x 3 ## date T38462 T38471 ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2015-11-10 2.4 -2.5 ## 2 2015-11-20 2 -2.2 ## 3 2015-11-30 4.6 -3.7 ## 4 2015-12-10 NA NA ## 5 2015-12-20 NA NA ## 6 2015-12-31 NA NA Finally, we remove the non observations again as above with the function na.omit. t_dec_filled_wide_tbl &lt;- t_dec_filled_wide_tbl %&gt;% na.omit() t_dec_filled_long_tbl &lt;- t_dec_filled_wide_tbl %&gt;% pivot_longer(-date) To deal with the missing values at the end of the observational record, we could also have used any other technique. Using the norm values however would have artificially reduced the variance in both cases as explained above. Furthermore and at least in the case of temperature, it is also questionable to what extent a norm calculated over the last 84 years is still representative given global warming. We will look in this important and interesting topic in the next section. 5.3.4 Anomalies and Outliers We use the function timetk::plot_anomaly_diagnostics to investigate anomalies in the time series. For discharge, we first log-transform the raw data with the following transformation to reduce the variance of the original data. \\[ \\hat{q}(t) = log(q(t) + 1) \\] where \\(\\hat{q}(t)\\) denotes the transformed discharge. Prior to the log transformation, 1 is added so as to avoid cases where discharge would be 0 and the logarithmic transform thus undefined. The transformation can easily be done with the log1p() function in R. Backtransformation via the function expm1() simply involves taking the exponent and subtracting 1 from the result. Figure ?? shows the result. The exceptionally wet year 19169 shows up as anomalous in the Chatkal River Basin and at the downstream Charvak Reservoir inflow gauge. , ?? and ?? show anomalies diagnostics of the available data. q_dec_filled_long_tbl %&gt;% plot_anomaly_diagnostics(date, value %&gt;% log1p(), .facet_vars = name, .frequency = 36, .interactive = T, .title = &quot;&quot;) Figure 5.5: Anomaly diagnostics of discharge data. The transparent grey band shows the width of the normal range. The highly anomalous wet year of 1969 is clearly visible in the discharge record of the Chatkal river basin (Station 16279). The investigation of precipitation anomalies shows a succession of regular anomalous wet events over time. It is interesting to see that the winter 1968/69 regularly anomalous at all three stations (Figure 5.6, zoom in to investigate). p_dec_filled_long_tbl %&gt;% plot_anomaly_diagnostics(date, value, .facet_vars = name, .interactive = TRUE, .title = &quot;&quot;) Figure 5.6: Anomaly diagnostics of precipitation data. While intuitively, we would have expected an eceptionally mild winter in 1968/69 due to the precipitation excess, the corresponding anomaly does not show up in the temperature record (Figure 5.7). t_dec_filled_long_tbl %&gt;% plot_anomaly_diagnostics(date,value, .facet_vars = name, .interactive = TRUE, .title = &quot;&quot;) Figure 5.7: Anomaly diagnostics of temperature data. Apart from the identification of extremal periods since as the 1969 discharge year in the Chatkal river basin, the diagnostics of anomalies also helps to identify likely erroneous data records. In Figure @ref(anomalies_T) for example, when we zoom into the data of the series T38471 in the first decade of the 21st century, problems in relation to positive anomalies during the winter are visible in 4 instances. One explanation would be that in at least some instances, the data are erroneously recorded as positive values when in fact they were negative (see dates ‘2002-01-31,’ ‘2005-01-10’ and ‘2007-02-28,’ Chatkal Station 38471). 5.3.5 Putting it all together Finally, we are now in the position to assemble all data that we will use for empirical modeling. The data is stored in long and wide form and used accordingly where required. For example, in Section @ref{TimeSeriesReg}, we are working with the wide data format to investigate model features in linear regression. Note that we also add a column with a decade identifier. Its use will become apparent in the Section 5.5 below. # Final concatenation data_wide_tbl &lt;- right_join(q_dec_filled_wide_tbl,p_dec_filled_wide_tbl,by=&#39;date&#39;) data_wide_tbl &lt;- right_join(data_wide_tbl,t_dec_filled_wide_tbl,by=&#39;date&#39;) # Add period identifiers (decades in this case) s &lt;- data_wide_tbl$date %&gt;% first() e &lt;- data_wide_tbl$date %&gt;% last() decs &lt;- decadeMaker(s,e,&#39;end&#39;) decs &lt;- decs %&gt;% rename(per=dec) data_wide_tbl &lt;- data_wide_tbl %&gt;% left_join(decs,by=&#39;date&#39;) # Creating long form data_long_tbl &lt;- data_wide_tbl %&gt;% pivot_longer(-date) # Cross checking completeness of record data_long_tbl %&gt;% group_by(name) %&gt;% summarize(n.na = sum(is.na(value)), n.na.perc = n.na/n()*100) ## # A tibble: 9 x 3 ## name n.na n.na.perc ## * &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 P38462 0 0 ## 2 P38464 0 0 ## 3 P38471 0 0 ## 4 per 0 0 ## 5 Q16279 0 0 ## 6 Q16290 0 0 ## 7 Q16924 0 0 ## 8 T38462 0 0 ## 9 T38471 0 0 ## Temp storage of data (remove later) # fPath &lt;- &#39;/Users/tobiassiegfried/Dropbox (hydrosolutions)/1_HSOL_PROJECTS/PROJECTS/SDC/DKU_WRM_COURSE_CA/Course Materials/Handbook/Applied_Hydrological_Modeling_Bookdown/temp/&#39; # saveRDS(data_wide_tbl,file=paste(fPath,&#39;data_wide_tbl&#39;,sep=&quot;&quot;)) # saveRDS(data_long_tbl,file=paste(fPath,&#39;data_long_tbl&#39;,sep=&quot;&quot;)) A consistent data record from 1933 until and including November 2015 is now prepared^Please note that by using left_join above, we have cut off discharge data from the year 1932 since we do not have meteorological data there.^. Let us analyze these data now. Please note that if you do not have the required package installed locally, you should install it prior to its use with the following command install.packages('simputation')↩︎ "],["Chap9-DataAnalysis.html", "5.4 Data Analysis", " 5.4 Data Analysis In this Section, the goal is to explore and understand the available time series data and their relationships and to take the necessary steps towards feature engineering. Features are predictors that we want to include in our forecasting models that are powerful in the sense that they help to improve the quality of forecasts in a significant manner. Sometimes, the modeler also wants to include synthetic features, i.e. predictors that are not observed but for example derived from observations. Different techniques are demonstrated that allow us to get familiar with the data that we are using. While we are interested to model discharge of Chatkal and Pskem rivers, it should be emphasized that all the techniques utilized for forecasting easily carry over to other rivers and settings. Let us start with a visualisation of the complete data record. Using timetk::plot_time_series and groups, we can plot all data into separate, individual facets as shown in Figure 5.8. data_long_tbl %&gt;% group_by(name) %&gt;% plot_time_series(date, value, .smooth = FALSE, .interactive = FALSE, .facet_ncol = 2, .title = &quot;&quot; ) Figure 5.8: Complete Data hydro-meteorological record for the zone of runoff formation in the Chirchik river basin. 5.4.1 Data Transformation It is interesting to observe that discharge values range over 2 - 3 orders of magnitude between minimum and maximum flow regimes. As can be seen in Figure 5.9, discharge and precipitation data are heavily skewed. When this is the case, it is generally advisable to consider data transformations as they help to improve predictive modeling accuracy of regression models. data_long_tbl %&gt;% group_by(name) %&gt;% ggplot(aes(x=value,colour = name)) + geom_histogram(bins=50) + facet_wrap(~name, scales = &quot;free&quot;) + theme(legend.position = &quot;none&quot;) Figure 5.9: Histograms of available raw data. Let us for example look at a very simple uniform non-parametric transformation, i.e. a logarithmic transformation (see Figure @ref(fig:histogramsData_transformed). As compared to parametric transformation, the logarithmic transformation is simple to apply for data greater than zero and does not require us to keep track of transformation parameters as, for example, is the case when we center and scale the data. data_wide_tbl %&gt;% mutate(across(Q16279:P38471,.fns = log1p)) %&gt;% # transforms discharge and precipitation time series pivot_longer(-date) %&gt;% ggplot(aes(x=value,colour = name)) + geom_histogram(bins=50) + facet_wrap(~name, scales = &quot;free&quot;) + theme(legend.position = &quot;none&quot;) (#fig:histogramsData_transformed)Histograms of transformed discharge and precipitation data together with the raw temperature data. Please note that with the base-R command log1p, 1 is added prior to the logarithmic transformation to avoid cases where the transformed values would not be defined, i.e. where discharge or precipitation is 0. More information about the log1p() function can be obtained by simply typing ?log1p. Recovering the original data after the log1p transformation is simply achieved by taking the exponent of the transformed data and subtracting 1 from the result. The corresponding R function is expm1(). Clearly, the log-transformed discharge values are no longer skewed (Figure @ref(fig:histogramsData_transformed)). We now see interesting bimodal distributions. At the same time, the variance of the transformed variables is greatly reduced. These are two properties that will help us construct a good model as we shall see below. Finally, the transformed discharge time series are shown in Figure @ref(). data_long_tbl %&gt;% filter(name==&#39;Q16279&#39; | name==&#39;Q16290&#39;) %&gt;% plot_time_series(date, log(value+1), .facet_vars = name, .smooth = FALSE, .interactive = FALSE, .title = &quot;&quot;, .y_lab = &quot;[-]&quot;, .x_lab = &quot;year&quot; ) (#fig:dischargeData_log1p)log1p() transformed discharge data. 5.4.2 Detecting Trends Lower frequency variability in time series, including trends, can be visualized by using the .smooth = TRUE option in the plot_time_series() function. To demonstrate this here, we have a closer look at the temperature data in our data record (Figure @ref(fig:T_trends)). data_long_tbl %&gt;% filter(name == &#39;T38462&#39; | name == &#39;T38471&#39;) %&gt;% plot_time_series(date, value, .smooth = TRUE, .facet_vars = name, .title = &quot;&quot;, .y_lab = &quot;deg. C.&quot;, .x_lab = &quot;year&quot; ) (#fig:T_trends)Temperature time series and trends. In both time series, a slight upward trend is visible that picks up over the most recent decades. We can look at these trends in greater detail, for example at monthly levels (Figure @ref(fig:T_monthly_trends)). data_long_tbl %&gt;% filter(name == &#39;T38462&#39;) %&gt;% summarise_by_time(.date_var = date, .by=&quot;month&quot;,value=mean(value)) %&gt;% tk_ts(frequency = 12) %&gt;% forecast::ggsubseriesplot(year.labels = FALSE) + geom_smooth(method = &quot;lm&quot;,color=&quot;red&quot;) + #ggtitle(&#39;Development of Monthly Mean Temperatures from 1933 - 2015 at Station 38462&#39;) + xlab(&#39;month&#39;) + ylab(&#39;Degrees Celsius&#39;) (#fig:T_monthly_trends)Sample development of Monthly Mean Temperatures from 1933 - 2015 at Station 38462. In the Figure above, a significant winter warming over the period of data availability is confirmed at Pskem meteorological station. As shown in Chapters 2 and 3, these trends are observed throughout the Central Asian region and are an indication of the changing climate there. We will have to take into account such type of trends in our modeling approach. 5.4.3 Auto- and Crosscorrelations A time series may have relationships to previous versions of itself - these are the ‘lags.’ The autocorrelation is a measure of the strength of this relationship of a series to its lags. The autocorrelation function ACF looks at all possible correlations between observation at different times and how they emerge. Contrary to that, the partial autocorrelation function PACF only looks at the correlation between a particular past observation and the current one. So in other words, ACF includes direct and indirect effects whereas PACF only includes the direct effects between observations at time t and the lag. As we shall see below, PACF is super powerful to identify relevant lagged timeseries predictors in autoregressive models (AR Models). Figure @ref(fig:Q_autocorr) shows the ACF and PACF over the interval of 72 lags (2 years). The AC function shows the highly seasonal characteristics of the underlying time series. It also shows the pronounced short-term memory in the basin, i.e. the tendency to observe subsequent values of high flows and subsequent values of low flow - hence the smoothness of the curve. This time of autocorrelation behavior is typical for basins with large surface storage in the form of lakes, swamps, snow and glaciers, permafrost and groundwater reserves (A. 2019). The Chatkal river basin certainly belongs to that category. data_long_tbl %&gt;% filter(name == &#39;Q16279&#39;) %&gt;% plot_acf_diagnostics(date, value, .show_white_noise_bars = TRUE, .lags = 72, .title = &quot;&quot; ) (#fig:Q_autocorr)Autocorrelation function (ACF) and partial autocorrelation function (PACF) are shown for the discharge time series at station 16279. But is there also autocorrelation of the annual time series? Let us test. Q16279_annual &lt;- data_long_tbl %&gt;% filter(name == &#39;Q16279&#39;) %&gt;% select(-name) %&gt;% summarize_by_time(.date_var = date, .by=&quot;year&quot;, sum=sum(value)*3600*24*10/10^9) Q16279_annual %&gt;% plot_time_series(date,sum, .smooth = FALSE, .title = &quot;&quot;, .x_lab = &quot;year&quot;, .y_lab = &quot;Discharge [cubic km per year]&quot;) Figure 5.10: Testing autocorrelation at annual scales for discharge at station 16279. Q16279_annual %&gt;% plot_acf_diagnostics(.date_var = date, .value = sum, .lags = 50, .show_white_noise_bars = TRUE, .title = &quot;&quot;, .x_lab = &quot;year&quot;) Figure 5.10: Testing autocorrelation at annual scales for discharge at station 16279. The above Figure @(fig:annualAutoCorr) shows a fast decaying autocorrelation function for the annualized time series where even lag 1 values are no longer correlated in a significant manner. The PAC function, on the other hand, demonstrates that lag 1 is really critical in terms of direct effects (Figure @ref(fig:Q_autocorr)). After that, the PACF tapers off quickly. To utilize these findings in our modeling approach that uses lagged regression is important, as we shall see below. We can also study cross-correlations between two different time series. In other words, in cross-correlation analysis between two different time series, we estimate the correlation one variable and another, time-shifted variable. For example, we can cross-correlate discharge at Gauge 16279 (Chatkal river) to discharge at Gauge 16290 (Pskem River) as shown in Figure @ref(fig:crosscor_Q). As is easily visible, the discharge behavior of the two rivers is highly correlated. data_wide_tbl %&gt;% plot_acf_diagnostics(date,Q16279, .ccf_vars = Q16290, .show_ccf_vars_only = TRUE, .show_white_noise_bars = TRUE, .lags = 72, .title = &quot;&quot; ) (#fig:crosscor_Q)Cross-correlation analysis of the two discharge time series Q16279 and Q16290. Converse to this, discharge shows a lagged response to temperature which is clearly visible in the cross-correlation function. data_wide_tbl %&gt;% plot_acf_diagnostics(date,T38471, .ccf_vars = Q16279, .show_ccf_vars_only = TRUE, .show_white_noise_bars = TRUE, .lags = 72, .title = &quot;&quot; ) (#fig:ccf_TQ)Cross-correlation between temperature at station 38471 and the discharge at station 16279. A less pronounced cross-correlation exists between precipitation and discharge when measured at the same stations (Figure @ref(ccf_PQ)). data_wide_tbl %&gt;% plot_acf_diagnostics(date,P38471, .ccf_vars = Q16279, .show_ccf_vars_only = TRUE, .show_white_noise_bars = TRUE, .lags = 72, .title = &quot;&quot; ) (#fig:ccf_PQ)Cross-correlation between temperature at station 38471 and the discharge at station 16279. 5.4.4 Time Series Seasonality There is a pronounced seasonality in the discharge characteristics of Central Asian rivers. One of the key reason of this is the annual melt process of the winter snow pack. Figure @ref(seasonalityDiagnostic_Q) shows the seasonality of the log-transformed discharge. These observations can help in investigating and detecting time-based (calendar) features that have cyclic or trend effects. data_long_tbl %&gt;% filter(name==&quot;Q16279&quot; | name==&quot;Q16290&quot;) %&gt;% plot_seasonal_diagnostics(date, log(value+1), .facet_vars = name, .feature_set = c(&quot;week&quot;,&quot;month.lbl&quot;,&quot;year&quot;), .interactive = FALSE, .title = &quot;&quot; ) (#fig:seasonalDiagnostic_Q)Seasonal diagnostics of log1p discharge. Weekly (top row), monthly (middle row) and yearly diagnostics (bottom row) are shown for the two discharge time series. Figure @ref(seasonalDiagnostic_P) shows the seasonal diagnostic for the log-transfomred precpitation time series. The significant interannual variability is visible. In the annualized time series, no trend is available. data_long_tbl %&gt;% filter(name==&quot;P38462&quot; | name==&quot;P38464&quot; | name==&quot;P38471&quot;) %&gt;% plot_seasonal_diagnostics(date, log1p(value), .facet_vars = name, .feature_set = c(&quot;week&quot;,&quot;month.lbl&quot;,&quot;year&quot;), .interactive = FALSE, .title = &quot;&quot; ) (#fig:seasonalDiagnostic_P)Seasonal Diagnostics of precipitation Weekly (top row), monthly (middle row) and yearly diagnostics (bottom row) are shown for the available precipitation data in the zone of runoff formation of the two tributary rivers. Finally, Figure @ref() displays the seasonal diagnostics of the temperature time series. Notice that we use untransformed, raw values here for plotting. data_long_tbl %&gt;% filter(name==&quot;T38462&quot; | name==&quot;T38471&quot;) %&gt;% plot_seasonal_diagnostics(date, value, .facet_vars = name, .feature_set = c(&quot;week&quot;,&quot;month.lbl&quot;,&quot;year&quot;), .interactive = FALSE, .title = &quot;&quot;, ) (#fig:seasonalDiagnostic_T)Seasonal Diagnostics of temperature Weekly (top row), monthly (middle row) and yearly diagnostics (bottom row) are shown for the available temperature data in the zone of runoff formation of the two tributary rivers. "],["Chap9FeatureEngineering.html", "5.5 Investigating and Engineering Predictors", " 5.5 Investigating and Engineering Predictors All the data that we have available have been analyzed by now and we can now move to generating a good and solid understanding of the relevance of predictors for statistical modeling. To start with, we will keep things deliberately simple. Our approach is tailored to the particular local circumstances and the needs and wants of the hydrometeorological agencies that are using such types of model to issue high quality forecasts. First, the plan here to start with the introduction and discussion of the current forecasting techniques that are used operationally inside the Kyrgyz Hydrometeorological agency. These models and their forecast quality will serve as benchmark to beat any of the other models introduced here. At the same time, we will introduce a measure with which to judge forecast quality. Secondly, we evaluate the simplest linear models using time series regression. This will also help to introduce and explain key concepts that will be discussed in the third and final section below. Finally, we show the application of more advanced forecasting modeling techniques that use state-of-the-art regression type algorithms. The forecasting techniques will be demonstrated by focussing on the Pskem river. The techniques extend to other rivers in the region and beyond in a straight forward manner. 5.5.1 Benchmark: Current Operational Forecasting Models in the Hydrometeorological Agencies 5.5.2 Time Series Regression Models The simplest linear regression model can be written as \\[ y_{t} = \\beta_{0} + \\beta_{1} x_{t} + \\epsilon_{t} \\] where the coefficient \\(\\beta_{0}\\) is the intercept term, \\(\\beta_{1}\\) is the slope and \\(\\epsilon_{t}\\) is the error term. The subscripts \\(t\\) denote the time dependency of the target and the explanatory variables and the error. \\(y_{t}\\) is our target variable, i.e. discharge in our case, that we want to forecast. At the same time, \\(x_{t}\\) is an explanatory variable that is already observed at time \\(t\\) and that we can use for prediction. As we shall see below, we are not limited to the inclusion of only one explanatory variable but can think of adding multiple variables that we suspect to help improve forecast modeling performance. To demonstrate the effects of different explanatory variables on our forcasting target and the quality of our model for forecasting discharge at stations 16290, the function plot_time_series_regression from the timetk package is used. First, we we only want to specify a model with a trend over the time \\(t\\). Hence, we fit the model \\[ y_{t} = \\beta_{0} + \\beta_{1} t + \\epsilon_{t} \\] model_formula &lt;- as.formula(log1p(Q16290) ~ as.numeric(date) ) model_data &lt;- data_wide_tbl %&gt;% select(date,Q16290) model_data %&gt;% plot_time_series_regression( .date_var = date, .formula = model_formula, .show_summary = TRUE, .title = &quot;&quot; ) ## ## Call: ## stats::lm(formula = .formula, data = .data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.3940 -0.7068 -0.2114 0.7193 2.0274 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.056e+00 1.489e-02 272.39 &lt;2e-16 *** ## as.numeric(date) -2.997e-06 1.675e-06 -1.79 0.0736 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7998 on 2983 degrees of freedom ## Multiple R-squared: 0.001073, Adjusted R-squared: 0.0007378 ## F-statistic: 3.203 on 1 and 2983 DF, p-value: 0.07359 Figure 5.11: Linear regression trend model. Note that the timetk::plot_time_series function is a convenience wrapper to make our lives easy in terms of modeling and immediately getting a resulting plot. The same model could be specified in the traditional R-way, i.e. as follows model_data %&gt;% lm(formula = model_formula) %&gt;% summary() ## ## Call: ## lm(formula = model_formula, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.3940 -0.7068 -0.2114 0.7193 2.0274 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.056e+00 1.489e-02 272.39 &lt;2e-16 *** ## as.numeric(date) -2.997e-06 1.675e-06 -1.79 0.0736 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7998 on 2983 degrees of freedom ## Multiple R-squared: 0.001073, Adjusted R-squared: 0.0007378 ## F-statistic: 3.203 on 1 and 2983 DF, p-value: 0.07359 The adjusted R-squared shows the medicore performance of our simple model as it cannot capture any of the seasonal variability. Furthermore we see that the trend coefficient is negative which indicates a decrease in mean discharge. However, as the p-value confirms, the trend is only significant at the 0.1 level. The first step in improving our model is to account for seasonality. In the case of decadal time series, we can add categorical variables (as factor variables) decoding the corresponding decades. Similarly, in the case of monthly data, we could use month names or factors 1..12 to achieve the same. The same reasoning extends to other periods (quarters, weekdays, etc.). We will use a quarterly model to explain the concept since the inclusion of 4 indicator variables for the individual quarters is easier to grasp than to work with 36 decadal indicators. # Computing quarterly mean discharge values q16290_quarter_tbl &lt;- model_data %&gt;% summarize_by_time(date,value=mean(log1p(Q16290)),.by = &quot;quarter&quot;) # adding quarters identifier q16290_quarter_tbl &lt;- q16290_quarter_tbl %&gt;% mutate(per = quarter(date) %&gt;% as.factor()) model_formula &lt;- as.formula(value ~ as.numeric(date) + per ) q16290_quarter_tbl %&gt;% plot_time_series_regression(date, .formula = model_formula, .show_summary = TRUE, .title = &quot;&quot; ) ## ## Call: ## stats::lm(formula = .formula, data = .data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.51477 -0.14936 0.00228 0.14410 0.66161 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.255e+00 2.204e-02 147.691 &lt; 2e-16 *** ## as.numeric(date) -3.158e-06 1.255e-06 -2.516 0.0123 * ## per2 1.551e+00 3.106e-02 49.919 &lt; 2e-16 *** ## per3 1.396e+00 3.107e-02 44.938 &lt; 2e-16 *** ## per4 2.562e-01 3.107e-02 8.248 3.98e-15 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2001 on 327 degrees of freedom ## Multiple R-squared: 0.9217, Adjusted R-squared: 0.9207 ## F-statistic: 962.4 on 4 and 327 DF, p-value: &lt; 2.2e-16 (#fig:trend_season_model)Example quarterly linear model with trend and seasonality. What we did here is to compare a continuous variable, i.e. the discharge, across 4 categories. Hence, we can write down the model in the following way: \\[ y_{t} = \\beta_{0} + \\beta_{1} \\delta_{t}^{Qtr2} + \\beta_{2} \\delta_{t}^{Qtr3} + \\beta_{3} \\delta_{t}^{Qtr4} + \\epsilon_{t} \\] Using ‘one hot encoding,’ we include only N-1 (here, 3) variables out of the N (here,4) in the regression because we can safely assume that if we are in Quarter 4, all the other indicator variables are simply 0. If we are in quarter 1 (Qtr1), the model would just be \\[ y_{t} = \\beta_{0} + \\epsilon_{t} \\] If we are in Quarter 2 (Qtr2), the model would be \\[ y_{t} = \\beta_{0} + \\beta_{1} + \\epsilon_{t} \\] since \\(\\delta_{t}^{Qtr2} = 1\\). Hence, whereas \\(\\beta_{0}\\) is to be interpreted as the estimated mean discharge in Quarter 1 (called (Intercept) in the results table below), \\(\\beta_{1}\\) (called qtr2 in the results table below) is the estimated difference of mean discharge between the two categories/quarters We can get the values and confidence intervals of the estimates easily in the following way lm_quarterlyModel &lt;- q16290_quarter_tbl %&gt;% lm(formula = model_formula) meanQtrEstimates &lt;- lm_quarterlyModel %&gt;% coefficients() meanQtrEstimates %&gt;% expm1() ## (Intercept) as.numeric(date) per2 per3 ## 2.493125e+01 -3.158103e-06 3.714894e+00 3.039112e+00 ## per4 ## 2.920533e-01 lm_quarterlyModel %&gt;% confint() %&gt;% expm1() ## 2.5 % 97.5 % ## (Intercept) 2.383084e+01 2.608043e+01 ## as.numeric(date) -5.627148e-06 -6.890525e-07 ## per2 3.435387e+00 4.012016e+00 ## per3 2.799662e+00 3.293653e+00 ## per4 2.154539e-01 3.734800e-01 The same reasoning holds true for the model with decadal observations to which we return now again. First, we add decades as factors to our data_wide_tbl. Now, we can specify and calculate the new model. model_formula &lt;- as.formula(log1p(Q16290) ~ as.numeric(date) + # trend components per # seasonality (as.factor) ) model_data &lt;- data_wide_tbl %&gt;% select(date,Q16290,per) model_data %&gt;% plot_time_series_regression( .date_var = date, .formula = model_formula, .show_summary = TRUE, .title = &quot;&quot; ) ## ## Call: ## stats::lm(formula = .formula, data = .data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.3225 -0.6972 -0.2318 0.7268 2.0364 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.943e+00 2.991e-02 131.827 &lt; 2e-16 *** ## as.numeric(date) -3.065e-06 1.670e-06 -1.836 0.0665 . ## per 6.150e-03 1.406e-03 4.374 1.26e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7974 on 2982 degrees of freedom ## Multiple R-squared: 0.00744, Adjusted R-squared: 0.006774 ## F-statistic: 11.18 on 2 and 2982 DF, p-value: 1.46e-05 (#fig:dec_trend_season_model)Decadal linear regression model with trend and seasonality. What we see is that through the inclusion of the categorical decade variables, we have greatly improved our modeling results since we can now capture the seasonality very well (Tip: zoom into the time series to compare highs and lows and their timing for the target variable and its forecast). However, despite the excellent adjusted R-squared value of 0.9117, our model is far from perfect as it is not able to account for inter-annual variability in any way. Let us quickly glance at the errors. lm_decadalModel &lt;- model_data %&gt;% lm(formula = model_formula) obs_pred_wide_tbl &lt;- model_data%&gt;% mutate(pred_Q16290 = predict(lm_decadalModel) %&gt;% expm1()) %&gt;% mutate(error = Q16290 - pred_Q16290) ggplot(obs_pred_wide_tbl, aes(x = Q16290, y = pred_Q16290, colour = per )) + geom_point() + geom_abline(intercept = 0, slope = 1) (#fig:scatterplot_Obs_vs_Fcst)Scatterplot of observed versus calculated values. We do not seem to make a systematic error as also confirmed by inspecting the histogram or errors (they are nicely centered around 0). ggplot(obs_pred_wide_tbl,aes(x=error)) + geom_histogram(bins=100) In Section @ref(Chap9_Autocorrelations) above, we saw that the PAC function is very high at lag 1. We exploit this fact be incorporating in the regression equation the observed previous discharge, i.e. \\(y_{t-1}\\) at time \\(t-1\\) to predict discharge at time \\(t\\). Hence, our regression can be written as \\[ y_{t} = \\beta_{0} + \\beta_{1} t + \\beta_{2} y_{t-1} + \\sum_{j=2}^{36} \\beta_{j} \\delta_{t}^{j} + \\epsilon_{t} \\] where the \\(\\delta_t^{j}\\) correspondingly are the 35 indicator variables as discussed above in the case of quarterly time series where we had 3 of these variables included. Before we can estimate this model, we prepare a tibble with the relevant data as shown in the table below (note that we simply renamed the discharge column to Q out of convenience). model_data &lt;- data_wide_tbl %&gt;% select(date,Q16290,per) %&gt;% rename(Q=Q16290) %&gt;% mutate(Q = log1p(Q)) %&gt;% mutate(Q_lag1 = lag(Q,1)) model_data ## # A tibble: 2,985 x 4 ## date Q per Q_lag1 ## &lt;date&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1933-01-10 3.37 1 NA ## 2 1933-01-20 3.23 2 3.37 ## 3 1933-01-31 3.17 3 3.23 ## 4 1933-02-10 3.21 4 3.17 ## 5 1933-02-20 3.26 5 3.21 ## 6 1933-02-28 3.28 6 3.26 ## 7 1933-03-10 3.30 7 3.28 ## 8 1933-03-20 3.53 8 3.30 ## 9 1933-03-31 3.57 9 3.53 ## 10 1933-04-10 3.92 10 3.57 ## # … with 2,975 more rows Notice that to accommodate the \\(y_{t-1}\\) in the data, we simply add a column that contains a lagged version of the discharge time series itself (see column Q_lag1). Now, for example, for our regression we have a first complete set of data points on \\(t = &#39;1933-01-20&#39;\\), with \\(Q=3.226844\\), \\(dec=2\\) and \\(Q_{lag1}=3.374169\\). Notice how the last value corresponds to the previously observed and now known \\(y_{t-1}\\). # Specification of the model formula model_formula &lt;- as.formula(Q ~ as.numeric(date) + per + Q_lag1) # Note that we use na.omit() to delete incomplete data records, ie. the first observation where we lack the lagged value of the discharge. model_data %&gt;% na.omit() %&gt;% lm(formula = model_formula) %&gt;% summary() ## ## Call: ## lm(formula = model_formula, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.09294 -0.12965 -0.03140 0.07656 1.17980 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.955e-01 1.801e-02 10.850 &lt;2e-16 *** ## as.numeric(date) -6.402e-08 3.925e-07 -0.163 0.87 ## per -7.010e-03 3.355e-04 -20.897 &lt;2e-16 *** ## Q_lag1 9.838e-01 4.353e-03 225.992 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1873 on 2980 degrees of freedom ## Multiple R-squared: 0.9453, Adjusted R-squared: 0.9452 ## F-statistic: 1.716e+04 on 3 and 2980 DF, p-value: &lt; 2.2e-16 It looks like we have made a decisive step in the right direction by incorporating the previously observed discharge value. Also, notice that some of the decade factors have lost their statistical significance meaning that the seasonality can now be captured in part also by the lagged version of the time series. Let us visualize the results quickly (tip: also zoom in to explore the fit). model_data %&gt;% na.omit() %&gt;% plot_time_series_regression( .date_var = date, .formula = model_formula, .show_summary = FALSE, # We do show the summary since we have plotted the summary output already above. .title = &quot;&quot; ) (#fig:lag_trend_season_Model)Linear regression model results with trend, seasonality and lag 1 predictors. This is clearly an astonishing result. Nevertheless, we should keep a couple of things in mind: What about the rate of change of the discharge and the acceleration of discharge? Would the incorporation of these features help to improve the model? We have not assess the quality of the forecasts using the stringent quality criteria as they exist in the Central Asian Hydrometeorological Services. How does our forecast perform under this criteria? Does the incorporation of precipitation and temperature data help to improve our forecast skills? We did not test our model on out-of-sample data. Maybe our model does not generalize well? We will discuss these and related issues soon when using more advanced models but for the time being declare this a benchmark model due to its simplicity and predictive power. We will work on these questions now and focus first on the incorporation of the rate of change in discharge and the acceleration of discharge over time. First, we add \\(Q_{lag2}\\) to our model data and then compute change and acceleration accordingly. model_data &lt;- model_data %&gt;% mutate(Q_lag2 = lag(Q,2)) %&gt;% mutate(change = Q_lag1 -Q_lag2) %&gt;% # that is the speed of change in discharge mutate(change_lag1 = lag(change,1)) %&gt;% mutate(acc = change - change_lag1) %&gt;% na.omit() # and that is the acceleration of discharge model_data ## # A tibble: 2,982 x 8 ## date Q per Q_lag1 Q_lag2 change change_lag1 acc ## &lt;date&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1933-02-10 3.21 4 3.17 3.23 -0.0614 -0.147 0.0860 ## 2 1933-02-20 3.26 5 3.21 3.17 0.0413 -0.0614 0.103 ## 3 1933-02-28 3.28 6 3.26 3.21 0.0551 0.0413 0.0138 ## 4 1933-03-10 3.30 7 3.28 3.26 0.0152 0.0551 -0.0399 ## 5 1933-03-20 3.53 8 3.30 3.28 0.0187 0.0152 0.00348 ## 6 1933-03-31 3.57 9 3.53 3.30 0.231 0.0187 0.212 ## 7 1933-04-10 3.92 10 3.57 3.53 0.0432 0.231 -0.187 ## 8 1933-04-20 4.05 11 3.92 3.57 0.348 0.0432 0.305 ## 9 1933-04-30 4.47 12 4.05 3.92 0.132 0.348 -0.216 ## 10 1933-05-10 4.88 13 4.47 4.05 0.416 0.132 0.284 ## # … with 2,972 more rows # Specification of the model formula model_formula &lt;- as.formula(Q ~ as.numeric(date) + per + Q_lag1 + change + acc) model_data %&gt;% na.omit() %&gt;% plot_time_series_regression( .date_var = date, .formula = model_formula, .show_summary = TRUE, # We do show the summary since we have plotted the summary output already above. .title = &quot;&quot; ) ## ## Call: ## stats::lm(formula = .formula, data = .data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.01892 -0.09223 -0.02294 0.05501 1.16531 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.574e-01 1.626e-02 15.830 &lt;2e-16 *** ## as.numeric(date) -1.834e-07 3.480e-07 -0.527 0.598 ## per -2.859e-03 3.318e-04 -8.616 &lt;2e-16 *** ## Q_lag1 9.496e-01 4.087e-03 232.331 &lt;2e-16 *** ## change 5.650e-01 2.002e-02 28.221 &lt;2e-16 *** ## acc -2.215e-01 1.806e-02 -12.265 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1658 on 2976 degrees of freedom ## Multiple R-squared: 0.9571, Adjusted R-squared: 0.957 ## F-statistic: 1.328e+04 on 5 and 2976 DF, p-value: &lt; 2.2e-16 model &lt;- model_data %&gt;% lm(formula=model_formula) model %&gt;% summary() ## ## Call: ## lm(formula = model_formula, data = .) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.01892 -0.09223 -0.02294 0.05501 1.16531 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.574e-01 1.626e-02 15.830 &lt;2e-16 *** ## as.numeric(date) -1.834e-07 3.480e-07 -0.527 0.598 ## per -2.859e-03 3.318e-04 -8.616 &lt;2e-16 *** ## Q_lag1 9.496e-01 4.087e-03 232.331 &lt;2e-16 *** ## change 5.650e-01 2.002e-02 28.221 &lt;2e-16 *** ## acc -2.215e-01 1.806e-02 -12.265 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1658 on 2976 degrees of freedom ## Multiple R-squared: 0.9571, Adjusted R-squared: 0.957 ## F-statistic: 1.328e+04 on 5 and 2976 DF, p-value: &lt; 2.2e-16 # Here, we add the the prediction to our tibble so that we can assess model predictive quality later. model_fc_wide_tbl &lt;- model_data %&gt;% mutate(pred = predict(model)) %&gt;% mutate(obs = expm1(Q), pred = expm1(pred)) %&gt;% select(date,obs,pred,per) model_fc_wide_tbl ## # A tibble: 2,982 x 4 ## date obs pred per ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1933-02-10 23.7 23.6 4 ## 2 1933-02-20 25.1 25.9 5 ## 3 1933-02-28 25.5 28.0 6 ## 4 1933-03-10 26 28.1 7 ## 5 1933-03-20 33. 28.3 8 ## 6 1933-03-31 34.5 38.1 9 ## 7 1933-04-10 49.3 38.9 10 ## 8 1933-04-20 56.4 58.0 11 ## 9 1933-04-30 86 65.3 12 ## 10 1933-05-10 130. 102. 13 ## # … with 2,972 more rows Another, albeit small improvement in the forecast of predicting discharge 1-step ahead! It is now time to properly gauge the quality of this seemingly excellent model. Does it conform to local quality standards that apply to decadal forecasts? The Figure @ref(benchmarkModel_obs_pred_comparison) shows the un-transformed data. We see that we are not doing so well during the summer peak flows. As we shall see further below, these are the notoriously hard to predict values, even just for 1-step ahead decadal predictions. model_fc_wide_tbl %&gt;% select(-per) %&gt;% pivot_longer(-date) %&gt;% plot_time_series(date, value, name, .smooth = F, .title = &quot;&quot;) 5.5.3 Assessing the Quality of Forecasts How well are we doing with our simple linear model? Let us assess the model quality using the local practices. For the Central Asian Hydromets, a forecast at a particular decade \\(d\\) is considered to be excellent if the following holds true \\[ |Q_{obs}(d,y) - Q_{pred}(d,y)| \\le 0.674 \\cdot \\sigma[\\Delta Q(d)] \\] where \\(Q_{obs}(d,y)\\) is the observed discharge at decade \\(d\\) and year \\(d\\), \\(Q_{pred}(d,y)\\) is the predicted discharge at decade \\(d\\) and year \\(y\\), \\(|Q_{obs}(d) - Q_{pred}(d)|\\) thus the absolute error and \\(\\sigma[\\Delta Q(d)] = \\sigma[Q(d) - Q(d-1)]\\) is the standard deviation of the difference of decadal observations at decade \\(d\\) and \\(d-1\\) over the entire observation record (hence, the year indicator \\(y\\) is omitted there). The equation above can be reformulated to \\[ \\frac{|Q_{obs}(d,y) - Q_{pred}(d,y)|}{\\sigma[\\Delta Q(d)]} \\le 0.674 \\] So let us assess the forecast performance over the entire record using the `riversCentralAsia::assess_fc_qual`` function. Note that the function returns a list of three objects. First, it returns a tibble of the number of forecasts that are of acceptable quality for the corresponding period (i.e. decade or month) as a percentage of the total number of observations that are available for that particular period. Second, it returns the period-averaged mean and third a figure that shows forecast quality in two panels. So, for our model which we consiedered to be performing well above, we get the following performance specs plot01 &lt;- TRUE te &lt;- assess_fc_qual(model_fc_wide_tbl,plot01) ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 te[[3]] In other words, roughly two thirds of our in-sample forecasts comply will be considered good enough when measured according to the quality criterion. Furthermore, the model performs worse than average during the second quarter (Q2) decades, i.e. from decade 10 through 17. This is an indication that providing good forecasts in Q2 might be hard. It is, however, generally not considered to be good practice to assess model quality on in-sample data. Rather, model performance should be assessed on out-of-sample data that was not used for model training and is thus data that is entirely unseen. 5.5.4 Generating and Assessing Out-of-Sample Forecasts We start off with our model_data tibble and want to divide it into two sets, one for model training and one for model testing. We refer to these sets as training set and test set. For the creation of these sets, we can use the timetk::time_series_split() function. 5.5.5 Machine Learning Models "],["save-data-for-hot-start.html", "5.6 Save Data for Hot Start", " 5.6 Save Data for Hot Start "],["RetrievalAnalysisHydroData.html", "Chapter 6 Retrieval &amp; Analysis of Data", " Chapter 6 Retrieval &amp; Analysis of Data Caution! - Work in progress. "],["preliminary-remarks.html", "Preliminary Remarks", " Preliminary Remarks We focus on the Chirchik River as our case study (see Section 3 for background information on the river basin). The steps for preparation and processing of the required input data for modeling carry over to any other basin that you wish to focus on. First, we will discuss how to prepare and process the geospatial information of the catchment and its sub-units using the open-source Geographic Information System QGIS. Second, we deal with climate data and show how to prepare existing temperature and precipitation data from local stations and also discuss how to access, download and process climate data from reanalysis products. Finally, we prepare the available hydrological data. : Make sure this is corresponding to the section’s content. For this course, we use the open source software RS MINERVE for physically-based modeling, i.e. for numerical rainfall-runoff modeling and river routing. We then use R for empirical modeling. Hence, the steps described here focus on the input requirements of this software. It should be noted, however, that other modeling packages exist with which hydrological-hydraulic modeling can be carried out in a similar manner. These include WEAP: Water Evaluation and Planning System, SWAT: Soil &amp; Water Assessment Tool, and Mike Hydro Basin As some of these modeling packages are license-based, the advantage of using the combination of QGIS, R and RS MINERVE is that this is a completely free software suit for any user and use scenario. : Maybe revise… In the Chapter @ref(HydroModels_PhysicalModels) below, we are going to show how to then use the data retrieved and prepared in RS MINERVE for numerical water balance modeling, streamflow routing and forecasting. : Maybe a good idea would be not to spend too much time on all of this GIS work and provide the relevant GIS raster and shapefiles upfront to the students and then just walk them through how to do this. Otherwise, this ends up being a GIS course in itself. "],["GeospatialData.html", "6.1 Geospatial Data", " 6.1 Geospatial Data 6.1.1 Catchment Delineation Catchment delineation is the first step in geospatial analysis5. This is a step-by-sep guide on how to setup, access, organize and analyze the relevant geo-spatial data for the Chirchik River basin. It is important to mention that this workflow can be utilized in any other catchment. STEP 1 Open Empty QGIS Project Open an empty QGIS Project and set Project Coordinate Reference System (CRS) to EPSG: 32642, WGS84 / UTM 42N (see Figure 6.1). Map projections try to portray the surface of the earth, or a portion of the earth, on a flat piece of paper or computer screen. In layman’s term, map projections try to transform the earth from its spherical shape (three-dimensional or 3D) to a planar shape (two-dimensional or 2D). A CRS then defines how the 2D, projected map in your GIS relates to real places on the earth. Generally, the decision of which map projection and CRS to use depends on the regional extent of the area you want to work in, on the analysis you want to do, and often also on the availability of data. Figure 6.1: Setting the CRS of the Project to EPSG: 32642, WGS84 / UTM 42N. As mentioned above, for the Chirchik River basin case study, we use the CRS EPSG: 32642, WGS84 / UTM 42N. The UTM CRS, where UTM stands for Universal Transverse Mercator, has its origin on the equator at a specific longitude. The Y-values increase southwards and the X-values increase to the West. The UTM CRS is a global map projection and is generally used all over the world. For accuracy reasons and to avoid too much distortion, the world is divided into 60 equal zones that are all 6 degrees wide in longitude from East to West. The UTM zones are numbered 1 to 60, starting at the anti-meridian (zone 1 at 180 degrees West longitude) and progressing East back to the antemeridian (zone 60 at 180 degrees East longitude). Figure 6.1 shows a global map of UTM zones. Figure 6.2: Global map of UTM zones. See QGIS online documentation for more information. When working on a particular catchment in any region on the planet, the corresponding UTM zone should be chosen. STEP 2 Adding Groups for Project Structuring It is important to keep your geospatial data properly organized. This can be achieved by using Groups in QGIS. You should follow this recommendation and now create the following groups in the Layers Panel: RIVERS, GAUGES, BASINS, DEM, POLITICAL and Temporary6. Once you start to generate a large number of raster and vector layers, these can be conveniently organized within these Groups which act in a similar way as electronic folders on your desktop (see Figure 6.3 for an example). Figure 6.3: Background map showing the area of interest. Note the Layers grouping in the panel on the left side. The contents in the folder show the geospatial assets that will be created as part of this tutorial. STEP 3 Background Map via QuickMapServices and Political Boundaries From the main menu, select Web/QuickMapServices/Google/Google Satellite or any other suitable map of your choice. If the QuickMapServices are not available by default, you have to install the corresponding plugin. More information can be found here. If by default the Google Map Service is not available, you just navigate to the Settings of the QuickMapServices plugin via QuickMapServices/Settings and go there to the tag ‘More Services’ where you should click the Button called ‘Get Contributed Pack.’ These additional map services then become available to you in the corresponding QuickMapServices list. Once the background map of your choice is visible as shown in Figure 6.3, you can zoom in on the area of interest, i.e., the mountain range north-east of Tashkent at the western end of the Tien Shan mountains, where the Chirchik River originates from its tributaries. For the political shapefiles, we download the relevant country-level data from the GADM database. GADM provides spatial data for all countries and their first- and second-level subdivisions in shapefile format. It is advisable to download all first-level administrative country border data for the Central Asian Republics. Finally, make sure that you import the correct shapefile data into the corresponding group, i.e. POLITICAL, in the QGIS Folder. STEP 4 Download the Digital Elevation Model (DEM) and Administrative Country Shapefiles As a next step, select first the DEM Group in the Layers Panel on the left and then load the SRTM Downloader QGIS Plugin. Zoom in on the region of interest including and up to the point where the Chirchik joins the Syr Darya towards the southwest. Open the plugin and then select Set Canvas Extent. Like this, the coordinates of the AoI get automatically filled in. If you press ‘Download,’ all the relevant SRTM tiles get downloaded. But first, the plug-in requests you to enter your username and password of your Earthdata login7. The download progress of the individual DEM tiles can be checked in the individual asset progress bars of the SRTM Downloader plugin. As these tiles are only temporary data, there is no need to specify an explicit Output-Path (unless you want to store them for later use in which case you should choose a dedicated output path). After the download, these individual raster tiles should be merged. Select them all in a first step and then merge them with the menu option Raster / Miscellaneous / Merge. An important remark is that after merging, the individual tiles can be deleted to safe disk space. Use the Mouse Right Click / Remove Layers option to do so. To check if all went well, the resulting DEM needs to be recolored. This can be achieved through right clicking on the merged DEM and selecting Properties / Symbology. In the Layer Properties Dialogue Box, the Singleband Pseudocolor option should be selected and then a new Colormap created from the catalogue ‘cpt-city.’ You can then choose any colormap that is suitable for topography coloring. One good choice is for example wiki-schwarzwald-cont. Finally, you have to reproject the DEM to the selected CRS EPSG:32642. STEP 5 Cutting the Area of Interest (AoI), DEM Resampling and Filling Sinks The downloaded DEM file is very likely much too big and it would be great to cut it to the rough shape that we are focussing on. We just have to ensure that all of our suspected catchment area is inside the cut out. For this purpose, we add a new shapefile Layer and make sure that its Geometry Type is correctly selected as ‘Polygon.’ Ensure also, that after the creation of the layer, it again is in a Projected CRS (UTM 42N). We can then toggle editing and use the polygon creation and edit tool to roughly outline the basin (AoI) that we are focusing on. In order to roughly cutout the AoI, select Extraction / Clip Raster by Mask Layer and select the corresponding layers in the user dialog box. Alternatively, you can just use the menu Raster / Clip Raster by Extent to draw or manually enter a rectangular clipping extent. Figure 6.4: After Checking the resolution of the downloaded SRTM DEM, we see that cell sizes are roughly 25 meters [m] in horizontal and vertical direction. For larger catchments, it is advisable to resample the DEM to a coarser resolution. There are many ways to do this in QGIS. Here, it is proposed to use the r.resample algorithm so as to decrease the resolution from 25 m to 100 m for later processing. Next, one has to ensure that sinks in the DEM are filled so that water does not get stuck on its way to the watershed outlet. First, use r.fill.dir to fill potential DEM gaps. The algorithm can be found in the Toolbox section once it is enabled in the dropdown menu Processing. Second, use r.watershed to generate the drainage direction and flow accumulation rasters. Note, it is important to specify a ‘Minimum size of exterior watershed basin’ (take 100’000) and also check the option ‘Use positive flow accumulation even for likely underestimates.’ As both, the drainage direction and flow accumulation rasters can be reused later, they should be permanently stored on disk, i.e. in the RIVERS group. STEP 6 Basin Delineation Once we have produced these rasters as described in STEP 5, we load the gauging stations if they are available as shapefiles. For each gauging station, we make sure that the gauge lies at the correct location by overlaying it with the Flow Accumulation Raster Data. If this is not the case, we need to relocate individual gauges so that they are at the correct location. This step is important so as to properly delineate the upstream area of a particular gauge under consideration. If gauges are not available as shapefiles, we can easily add a new shapefile layer and then define one or more gauges in that layer for which we want to delineate basin shapes. Ordered by their 5-digit code as administered by the Uzbek Hydrometeorological Service, the important gauges to consider in the Chirchik river basin are: id = 16275, name = Chinaz Gauge, river Chirchik River, lat = 4’528’236, lon = 479’463 id = 16279, name = Khudaydod Gauge, river = Chatkal River, lat = 4’596’628, lon = 598’278 id = 16290, name = Mullala Gauge, river = Pskem River, lat = 597’351, lon = 4’622’724 id = 16294, name = Virtual Gauge, river = Inflow to Charvak Reservoir, lat = 584’616, lon = 4’609’108 id = 16298, name = Sidhzak Gauge, river = Nauvalisoy River, lat = 4’618’690, lon = 589’674 id = 16300, name = Khodizhkent Gauge, river = Ugam River, lat = 4’610’070, lon = 578’612 Finally, with the algorithm r.water.outlet, and by using the Drainage Direction Map, we map those basins and get individual basin raster maps. To distinguish between the zone of runoff formation and the zone of water distribution and consumption in the larger catchment, we propose to use an artificial Gauge just below the Charvak Reservoir dam to delineate the upstream area and to then use the Geoprocessing Tool Union to merge these two polygons of upstream dam area and Ugam subcatchment into one zone of runoff formation. In principle, we are now ready to build a first rough model that does not rely on further reinfinement of the individual subcatchments. STEP 7 RIVER DELINEATION (OPTIONAL) This step is not strictly required but is simply used to define the topology of the rivers and tributaries properly. However and together with the other relevant layers, the resulting rivers shapefile can be used in the GIS Section of RS MINERVE for modeling. It can be generated easily by selecting the Flow Accumulation raster and the using the raster calculator to generate a binary 0/1 raster for the major stream segments only8. While you can experiment with arbitrary cutoff levels, a good value is 10’000. Hence, the raster calculator command to apply is ( @FlowAccumulation &gt; 10000 ) under the assumption that your flow accumulation layer is named accordingly. The resulting raster can finally be vectorized to arrive at the river network. It is advisable to perform a Vector Geometry / Fix Geometries correction on the resulting vector layer as there are likely self-intersections the processing of the layer. Once this is done, the layer can be clipped to the basin extent should this still be required. STEP 8 POLYGONIZATION OF SUBCATCHMENTS The rainfall-runoff model that we are using accounts for runoff generation processes in different contributing subcatchments. Depending on the average altitude of these, the timing and magnitude of snow- and glacier-melt contributions might highly vary throughout a hydrological year. The same is true within these individual contributing subcatchments where snow melt in lower elevations starts earlier than at higher elevations due to the negative temperature lapse rate. To account for these phased in time processes, the subcatchments can be discretized into elevation bands of a typical width. A sensible choice in the context of the Chirchik River Basin is to use elevation bands of 500 meters spacing and then model the relevant processes for each of these bands as if they were individual contributing smaller separate sub-subcatchments that dewater all to the same place. With the QGIS raster to vector option, we polygonize the basins. Check the validity of the polygon with Vector Geometry/Check Validity and correct, where necessary. 6.1.2 Computation of Elevation Bands With the reclassification algorithm, we create elevation band polygons based on the DEM layer. First, we smooth the DEM to simplify the elevation bands a bit. Then, we Reclassify by Table the DEM into the desired elevation bands. For the exercise here and given the specific topography of the basin(s) that we are interested in our Case Study, we enter manually altitude bands that are 500 meters apart (see Figure @ref{fig:ReclassificationByTable}). As output, we get a raster map with the individual elevation classes. The prepared DEM elevation levels range from 0 masl to 4’176 masl over the whole catchment. From the Figure 6.5: Reclassifying a DEM to make elevation classes that cover a range of 500 meters. Using the elevation band raster map, we use GDAL / Raster Conversion / Polygonize to create the elevation band polygons. Polygon clipping with SAGA/Vector Polygon Tool/Polygon Clipping tool to arrive and subcatchment level basins with altitude bands. Now, we have derived the required shapefiles. For importing into the rainfall-runoff model in RS MINERVE, we have to now properly prepare their attribute tables. This is a somewhat lengthy and tedious process but will help later greatly in terms of automatic model creation in RS MINERVE. RS Minerve requires the following GIS layers for the automatic translation into a rainfall-runoff model, i.e. subbasins.shp, junctions.shp and rivers.shp (see (Foehn et al. 2020) for more details). The individual feature attributes should be added either at the time of the layer creation or with the field calculator in QGIS. (#fig:RSMINERVE_GIS)Default Shapefile layers required in RS MINERVE to simplify the model topology building. See (Foehn et al. 2020) for more information. //FIXME: Check what to do with this! We note that for water supplies in the rainfall/runoff model, the focus is on the zone of runoff formation. //TODO: Add GLIMS global land ice data. STEP 9 INTEGRATION OF GLACIER DATA For the retrieval of data on land ice, we will utilize GLIMS data. Here, we largely follow a blog post by Craig Dsouza where the process of catchment delineation is nicely described (see this link for more information)↩︎ Of course, this grouping is just a suggestion and the user is free to organize spatial assets according to his/her own liking↩︎ If you do not have a login, you can create one at (https://urs.earthdata.nasa.gov//users/new){target=“_blank”}↩︎ Remember, the flow accumulation matrix entries correspond to the accumulated number of cells flowing into that particular cell (assuming equal weights for the calculation)↩︎ "],["climate-data.html", "6.2 Climate Data", " 6.2 Climate Data This Section requires the following R packages to be installed. If you are running R in RStudio and some of the packages are not yet installed on your computer, RStudio will warn you and ask, whether you want to have them installed. //TODO: Suppress output below # Tidyverse library(tidyverse) # File navigation library(here) ## here() starts at /Users/tobiassiegfried/Dropbox (hydrosolutions)/1_HSOL_PROJECTS/PROJECTS/SDC/DKU_WRM_COURSE_CA/CourseMaterials/Handbook/Applied_Hydrological_Modeling_Bookdown # Copernicus Climate Data Store library(ecmwfr) library(keyring) # Handling netcdf files library(ncdf4) # Spatial data plotting &amp; plotting #library(rgdal) library(raster) ## Loading required package: sp ## ## Attaching package: &#39;raster&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## select ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract library(rgeos) ## rgeos version: 0.5-5, (SVN revision 640) ## GEOS runtime version: 3.8.1-CAPI-1.13.3 ## Linking to sp version: 1.4-2 ## Polygon checking: TRUE library(sp) library(sf) ## Linking to GEOS 3.8.1, GDAL 3.1.4, PROJ 6.3.1 library(rasterVis) ## Loading required package: lattice ## Loading required package: latticeExtra ## ## Attaching package: &#39;latticeExtra&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## layer library(RColorBrewer) 6.2.1 Access, Select and Download ERA5 Reanalysis Data For the climate data to be used in the modeling approach, we use ERA5 data from the European Center for Medium-Range Weather Forecasts (ECMWF, &lt;www.ecmwf.int&gt;). ERA5, the successor to ERA-Interim, provides global, hourly estimates of atmospheric variables, at a horizontal resolution of 31 km and 137 vertical levels from the surface to 0.01 hPa (Dee D. 2020). ERA5 presently extends back to 1979 but will ultimately be extended back to 19509. The ERA5 data is available via the Copernicus Climate Store at https://cds.climate.copernicus.eu. However, before we can access, select and download it there, each user has to register with a personal account in the store. For this purpose, the user should navigate to the website and register via the Login/Register/NewAccount Menu. You will receive an email once your account is ready. Log in to your account and go to your user profile where you find your user ID and API key. The relevant information should be copied and into the relevant places of the code chunk below and then be executed. #Note: replace the UID and key strings below with the proper user&#39;s information in your Copernicus Climate Data Store account. UID &lt;- &#39;UID&#39; API_key &lt;- &#39;key&#39; #This function links your password and user id for later steps wf_set_key(UID, API_key, &#39;cds&#39;) //TODO: output still showing. How to deal with it? If all worked well, you will get the following confirmation in the console: ## User UID for cds service added successfully On the Copernicus website, make sure that you are logged into your account and the navigate to Datasets. There, search for the Product ‘ERA5-Land monthly averaged data from 1981 to present’ and select it10. You end up on the products homepage where you can get more information and download the data via a form where you select the product’s type, variables, the years, months and time of day, the geographical area and, finally, the download file format of interest. Please select the following: Product type: Monthly averaged reanalysis Variable: Temperature: 2 m Temperature Lakes: NA Snow: NA Soil Water: NA Radiation and Heat: NA Evaporation and Runoff: Potential evaporation Wind, Pressure and Precipitation: Total precipitation Vegetation: NA Year: Select all Month: Select all Time: 00:00 Geographical area: Sub-region extraction (West = 65, East = 80, South = 35, North = 45) Format: NetCDF (experimental) Accept the Terms of use and press the ‘Show API request button.’ You should see the following Python request now as shown in Figure 6.6. Figure 6.6: Screenshot showing the Copernicus Data Store API request that can be copied and posted into RStudio for the convenient download of the data there. The request should be copied and pasted into RStudio into your current .Rmd file there. Select the python request with the cursor and choose ‘ECMWFR/Python to List’ under the Addins Menu. The python request will then automatically be translated into a an r command. Please check that everything is ok by comparing it with a correct request as shown below. Also, please note that we have changed the target file name by specifying target = reanalysis-era5-land-monthly-means_CentralAsia.nc. In a final step, the user can then download the data with the wf_request() function. # Here is is the resulting request in R language request &lt;- list(&quot;dataset_short_name&quot; = &quot;reanalysis-era5-land-monthly-means&quot;, format = &quot;netcdf&quot;, product_type = &quot;monthly_averaged_reanalysis&quot;, variable = c(&#39;2m_temperature&#39;, &#39;potential_evaporation&#39;, &#39;total_precipitation&#39;), year = c(&#39;1981&#39;, &#39;1982&#39;, &#39;1983&#39;, &#39;1984&#39;, &#39;1985&#39;, &#39;1986&#39;, &#39;1987&#39;, &#39;1988&#39;, &#39;1989&#39;, &#39;1990&#39;, &#39;1991&#39;, &#39;1992&#39;, &#39;1993&#39;, &#39;1994&#39;, &#39;1995&#39;, &#39;1996&#39;, &#39;1997&#39;, &#39;1998&#39;, &#39;1999&#39;, &#39;2000&#39;, &#39;2001&#39;, &#39;2002&#39;, &#39;2003&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2006&#39;, &#39;2007&#39;, &#39;2008&#39;, &#39;2009&#39;, &#39;2010&#39;, &#39;2011&#39;, &#39;2012&#39;, &#39;2013&#39;, &#39;2014&#39;, &#39;2015&#39;, &#39;2016&#39;, &#39;2017&#39;, &#39;2018&#39;, &#39;2019&#39;, &#39;2020&#39;), month = c(&quot;01&quot;, &quot;02&quot;, &quot;03&quot;, &quot;04&quot;, &quot;05&quot;, &quot;06&quot;, &quot;07&quot;, &quot;08&quot;, &quot;09&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;), time = &quot;00:00&quot;, area = &quot;45/65/35/80&quot;, #dataset = &quot;reanalysis-era5-land-monthly-means&quot;, target = &quot;reanalysis-era5-land-monthly-means_CentralAsia.nc&quot; ) # Download data as netcdf file and store it in the directory where you are running this script, this returns the path to the file ncfilelink &lt;- wf_request(user = UID, request = request, transfer = TRUE, path = here(), verbose = TRUE) ## [1] &quot;moved temporary file to -&gt; /.../reanalysis-era5-land-monthly-means_CentralAsia.nc&quot; ## [1] &quot;request purged from queue!&quot; Some Sources on NetCDF and raster files: Here are some good resources to get you started: https://pjbartlein.github.io/REarthSysSci/index.html and https://cmerow.github.io/RDataScience/05_Raster.html. Although this is an extraordinary product, users still need to be aware of the limitations of reanalysis; two of the major ones are that non-physical trends and variability may be present in the record due to changes in the observing system, and that the climatologies of some variables, like surface energy fluxes, are not well represented.↩︎ The direct link is https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land-monthly-means?tab=form.↩︎ "],["hydrological-data.html", "6.3 Hydrological Data", " 6.3 Hydrological Data //TODO: Show added value from consulting data from altimetry https://dahiti.dgfi.tum.de/en/map/ Maybe show some analysis in KNMI CLimateExplorer? "],["HydroModelsPhysicalModels.html", "Chapter 7 Hydrologic-Hydraulic Modeling", " Chapter 7 Hydrologic-Hydraulic Modeling Caution! - Work in progress. "],["background-on-physically-based-modeling.html", "7.1 Background on Physically-Based Modeling", " 7.1 Background on Physically-Based Modeling "],["model-setup.html", "7.2 Model Setup", " 7.2 Model Setup 7.2.1 Zone of Runoff Formation 7.2.2 Zone of Water Distribution and Consumption "],["model-calibration-and-validation.html", "7.3 Model Calibration and Validation", " 7.3 Model Calibration and Validation "],["discussion.html", "7.4 Discussion", " 7.4 Discussion "],["Operationalization.html", "Chapter 8 Operationalization of Models - Opportunities and Challenges", " Chapter 8 Operationalization of Models - Opportunities and Challenges Caution! - Work in progress. "],["co-design-phase.html", "8.1 Co-design Phase", " 8.1 Co-design Phase "],["modeling-phase.html", "8.2 Modeling Phase", " 8.2 Modeling Phase "],["testing-phase.html", "8.3 Testing Phase", " 8.3 Testing Phase "],["operational-deployment.html", "8.4 Operational Deployment", " 8.4 Operational Deployment "],["Appendix.html", "Chapter 9 (APPENDIX) Appendix", " Chapter 9 (APPENDIX) Appendix "],["appendix-a.html", "Chapter 10 Appendix A ", " Chapter 10 Appendix A "],["open-source-software.html", "10.1 Open-Source Software", " 10.1 Open-Source Software 10.1.1 QGIS 10.1.2 R and RStudio 10.1.3 RS Minerve "],["References.html", "Chapter 11 References", " Chapter 11 References A., Cancelliere. 2019. “Statistical Analysis of Hydrologic Variables.” In, edited by Stedinger Teegavarapu R. S. V. Salas J. D., 203–29. ASCE. Aizen, V B, E M Aizen, and V A Kuzmichonok. 2007. “Glaciers and Hydrological Changes in the Tien Shan: Simulation and Prediction.” Environmental Research Letters 2 (4): 045019. https://doi.org/10.1088/1748-9326/2/4/045019. Central Intelligence Agency. n.d. “The World Factbook 2020.” https://www.cia.gov/library/publications/resources/the-world-factbook/index.html. Dee D., National Center for Atmospheric Research Staff. 2020. “The Climate Data Guide: Era5 Atmospheric Reanalysis.” https://climatedataguide.ucar.edu/climate-data/era5-atmospheric-reanalysis. Foehn, A., J. Garcia Hernandez, B. Roquier, J. Fluixa-Sanmartin, T. Brauchli, J. Paredes Arquiola, and G. De Cesare. 2020. “RS MINERVE - User Manual, V2.15.” ISSN 2673-2653. Switzerland: Ed. CREALP. Garcia Hernandez, J., A. Foehn, J. Fluixa-Sanmartin, B. Roquier, T. Brauchli, J. Paredes Arquiola, and De Cesare G. 2020. “RS MINERVE - Technical Manual, V2.25.” ISSN 2673-2661. Switzerland: Ed. CREALP. Gerlitz, Lars, Eva Steirou, Christoph Schneider, Vincent Moron, Sergiy Vorogushyn, and Bruno Merz. 2018. “Variability of the Cold Season Climate in Central Asia. Part I: Weather Types and Their Tropical and Extratropical Drivers.” Journal of Climate 31 (18): 7185–7207. https://doi.org/10.1175/jcli-d-17-0715.1. GLIMS, and NSIDC. 2005, updated 2018. Global Land Ice Measurements from Space Glacier Database. Compiled and made available by the international GLIMS community and the National Snow and Ice Data Center, Boulder CO, U.S.A. DOI:10.7265/N5V98602. Pravilova, Ekaterina. 2009. “River of Empire: Geopolitics, Irrigation, and the Amu Darya in the Late XIXth Century.” Cahiers d’Asie Centrale 17/18: 255–87. QGIS Development Team. 2021. QGIS Geographic Information System. QGIS Association. R Core Team. 2013. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. http://www.R-project.org/. Shults, Victor. 1965. Rivers of Middle Asia. 2nd Edition. Gidrometeoizdat, Leningrad. “Srtmgl1 n -ASA SRTM Version 3.0.” 2020. https://earthdata.nasa.gov/learn/articles/nasa-shuttle-radar-topography-mission-srtm-version-3-0-global-1-arc-second-data-released-over-asia-and-australia. Team’, ’RStudio. 2020. RStudio: Integrated Development Environment for r. Boston, MA: RStudio, PBC. "]]
